{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 4 Project - Kaggle Competition \"Natural Language Processing with Disaster Tweets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been accumulated from a number of tweets, some of which are about disasters, some of which are not. By creating a model for Natural Language Processing (NLP), we can predict whether or not a given tweet is about a real disaster or not. This can benefit companies who wish to monitor twitter in the event of an emergency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np \n",
    "import nltk\n",
    "np.random.seed(42)\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what is NOT a disaster tweet:\n",
    "train_df[train_df[\"target\"] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what IS a disaster tweet:\n",
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore other features\n",
    "# word frequencies for keyword column in 1 vs 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "armageddon               42\n",
       "deluge                   42\n",
       "damage                   41\n",
       "body%20bags              41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"keyword\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing the top 10 keywords in both train_df and test_df to see if we notice any trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deluge</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>armageddon</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harm</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sinking</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>body%20bags</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>damage</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>evacuate</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fear</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>twister</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  keyword\n",
       "0   fatalities       45\n",
       "1       deluge       42\n",
       "2   armageddon       42\n",
       "3         harm       41\n",
       "4      sinking       41\n",
       "5  body%20bags       41\n",
       "6       damage       41\n",
       "7     evacuate       40\n",
       "8         fear       40\n",
       "9      twister       40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_train_keywords = train_df['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_train_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_train_keywords['index'], x=top_train_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deluged</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rubble</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demolished</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snowstorm</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sirens</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annihilation</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seismic</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>first%20responders</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>obliteration</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>survivors</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  keyword\n",
       "0             deluged       23\n",
       "1              rubble       22\n",
       "2          demolished       22\n",
       "3           snowstorm       21\n",
       "4              sirens       21\n",
       "5        annihilation       21\n",
       "6             seismic       21\n",
       "7  first%20responders       21\n",
       "8        obliteration       21\n",
       "9           survivors       20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_test_keywords = test_df['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_test_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_test_keywords['index'], x=top_test_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing what proportion of the training data are disaster tweets and non-disaster tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['target'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing the top 10 keywords for the train_df for each target value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweets = train_df[train_df['target']==1]\n",
    "\n",
    "other_tweets = train_df[train_df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>10834</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cramer: Iger's 3 words that wrecked Disney's s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>10837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These boxes are ready to explode! Exploding Ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>10841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sirens everywhere!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>10848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I just heard a really loud bang and everyone i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4342 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword location  \\\n",
       "15       23      NaN      NaN   \n",
       "16       24      NaN      NaN   \n",
       "17       25      NaN      NaN   \n",
       "18       26      NaN      NaN   \n",
       "19       28      NaN      NaN   \n",
       "...     ...      ...      ...   \n",
       "7581  10833  wrecked  Lincoln   \n",
       "7582  10834  wrecked      NaN   \n",
       "7584  10837      NaN      NaN   \n",
       "7587  10841      NaN      NaN   \n",
       "7593  10848      NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "15                                       What's up man?       0  \n",
       "16                                        I love fruits       0  \n",
       "17                                     Summer is lovely       0  \n",
       "18                                    My car is so fast       0  \n",
       "19                         What a goooooooaaaaaal!!!!!!       0  \n",
       "...                                                 ...     ...  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "7582  Cramer: Iger's 3 words that wrecked Disney's s...       0  \n",
       "7584  These boxes are ready to explode! Exploding Ki...       0  \n",
       "7587                                 Sirens everywhere!       0  \n",
       "7593  I just heard a really loud bang and everyone i...       0  \n",
       "\n",
       "[4342 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wreckage</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outbreak</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>derailment</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debris</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil%20spill</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>typhoon</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suicide%20bombing</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>evacuated</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rescuers</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index  keyword\n",
       "0           wreckage       39\n",
       "1           outbreak       39\n",
       "2         derailment       39\n",
       "3             debris       37\n",
       "4        oil%20spill       37\n",
       "5            typhoon       37\n",
       "6     suicide%20bomb       32\n",
       "7  suicide%20bombing       32\n",
       "8          evacuated       32\n",
       "9           rescuers       32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_dis_keywords = disaster_tweets['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_dis_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_dis_keywords['index'], x=top_dis_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body%20bags</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>armageddon</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harm</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deluge</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ruin</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>twister</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fear</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>explode</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>siren</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  keyword\n",
       "0  body%20bags       40\n",
       "1   armageddon       37\n",
       "2         harm       37\n",
       "3      wrecked       36\n",
       "4       deluge       36\n",
       "5         ruin       36\n",
       "6      twister       35\n",
       "7         fear       35\n",
       "8      explode       35\n",
       "9        siren       35"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_other_keywords = other_tweets['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_other_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_other_keywords['index'], x=top_other_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({nan: 61, 'fatalities': 45, 'armageddon': 42, 'deluge': 42, 'body%20bags': 41, 'damage': 41, 'harm': 41, 'sinking': 41, 'collided': 40, 'evacuate': 40, ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "train_freq_dist = FreqDist(train_df[\"keyword\"].explode())\n",
    "train_freq_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = train_df.text\n",
    "y = train_df.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import emoji\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "for tweet in train_df['text']:    \n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    #tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         if w.lower() in words or not w.isalpha()) #Remove non-english tweets (not 100% success)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace smoothing ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculating the probabilities of disaster and non-disaster tweets in the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4296597924602653\n",
      "0.5703402075397347\n"
     ]
    }
   ],
   "source": [
    "P_disasters = len(disaster_tweets) /(len(disaster_tweets)+len(other_tweets))\n",
    "P_non = len(other_tweets) /(len(other_tweets)+len(disaster_tweets))\n",
    "print(P_disasters)\n",
    "print(P_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need set of unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = (tuple(nltk.bigrams(X_train,pad_left=True, pad_right=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigr = nltk.bigrams(X_train,pad_left=True, pad_right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalFreqDist with 5650 conditions>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencyDist = nltk.ConditionalFreqDist(bigr)\n",
    "frequencyDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laplace smoothing = used to correct probabilities of words so there are no zeroes\n",
    "#categories will be 1 and 0\n",
    "def vocab_maker(category):\n",
    "    vocab_category = set()\n",
    "    \n",
    "    for tweet in category:\n",
    "        words = tweet.split()\n",
    "        for word in words:\n",
    "            vocab_category.add(word)\n",
    "    return vocab_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dis = vocab_maker(disaster_tweets['text'])\n",
    "voc_non = vocab_maker(other_tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21',\n",
       " 'Ns',\n",
       " 'primarily...',\n",
       " '@traplord_29',\n",
       " 'http://t.co/Ch6E7vTATR',\n",
       " 'http://t.co/ct2JUtvYTg',\n",
       " 'CHONCE',\n",
       " '#AdiosSuperBacterias',\n",
       " 'Force...',\n",
       " 'ET',\n",
       " 'veteran',\n",
       " 'INFO',\n",
       " 'trickshot',\n",
       " 'http://t.co/2o7Eva1cOe',\n",
       " 'blight...',\n",
       " \"Night'\",\n",
       " '#spain',\n",
       " 'Shadowflame',\n",
       " '($)',\n",
       " 'Half',\n",
       " 'Ending',\n",
       " 'proper',\n",
       " 'DROID',\n",
       " 'ETO',\n",
       " '5.139055',\n",
       " 'http://t.co/mFSw0tYstA',\n",
       " 'efforts',\n",
       " 'You)',\n",
       " 'seatbelt!!!...',\n",
       " 'http://t.co/itZzKWfhG5',\n",
       " 'paulista',\n",
       " 'DOWN',\n",
       " 'Wed...',\n",
       " 'http://t.co/R33nCvjovC',\n",
       " '(415)',\n",
       " 'http://t.co/vVE3UsesGf',\n",
       " 'body-bagging',\n",
       " '#US?',\n",
       " 'occupants',\n",
       " '4:30',\n",
       " 'hostage!',\n",
       " '#iJETalerts',\n",
       " 'interactions.',\n",
       " 'scum',\n",
       " 'y',\n",
       " 'harbor',\n",
       " 'roller.',\n",
       " 'burned:',\n",
       " 'RT?',\n",
       " 'standard',\n",
       " 'http://t.co/1RrEO2jG9u',\n",
       " '@accionempresa',\n",
       " 'http://t.co/3bwWNLsxhB',\n",
       " \"bomb'\",\n",
       " '#CNN',\n",
       " '@LindaSOCVAT',\n",
       " 'knew.',\n",
       " 'time)',\n",
       " 'http://t.co/5FcJVMl520',\n",
       " 'SlideShare',\n",
       " '1976.',\n",
       " '2.4RegionåÊåÊNEAR',\n",
       " 'remixes.',\n",
       " 'http://t.co/7IEiZ619h0',\n",
       " 'http://t.co/2kdq56xTWs',\n",
       " '(Black)',\n",
       " 'Nearly',\n",
       " 'Overload',\n",
       " 'rolo',\n",
       " 'explosion.',\n",
       " '@eileenmfl',\n",
       " 'WOULD',\n",
       " \"Pelosi's\",\n",
       " 'disaster?',\n",
       " 'Phase',\n",
       " 'slipping',\n",
       " 'principle',\n",
       " '@fouseyTUBE',\n",
       " 'Prosser',\n",
       " 'http://t.co/7LhKJz0IVO',\n",
       " 'dislocation',\n",
       " 'sinkhole',\n",
       " 'HAIL',\n",
       " 'BBM',\n",
       " 'BOY',\n",
       " 'Finnish',\n",
       " 'Morning',\n",
       " 'Systems',\n",
       " 'rails.',\n",
       " 'http://t.co/wMmkIrJ0Hw',\n",
       " 'Manager',\n",
       " 'meat',\n",
       " 'http://t.co/xe0EE1Fzfh',\n",
       " 'LZKTJNOX',\n",
       " 'http://t.co/LRelVrm06w',\n",
       " './.....hmm',\n",
       " '#NatsNation',\n",
       " 'split',\n",
       " '@AIIAmericanGirI',\n",
       " 'contained',\n",
       " '600!!!',\n",
       " 'http://t.co/GPBXRrDc07',\n",
       " '#CCMusic',\n",
       " '#environment',\n",
       " 'fuck',\n",
       " 'fleek',\n",
       " 'password',\n",
       " 'Frank',\n",
       " 'Maiga',\n",
       " '?????FOLLOWBACK',\n",
       " 'Full',\n",
       " 'lakes',\n",
       " '@Jolly_Jinu',\n",
       " 'Vikings',\n",
       " 'issue?',\n",
       " \"terrorist's\",\n",
       " 'pacific',\n",
       " 'http://t.co/4k8OLZv9bV',\n",
       " 'offensive',\n",
       " 'Stories',\n",
       " \"rts'&amp;'democracy'.\",\n",
       " 'time.',\n",
       " 'Logan',\n",
       " 'Peel',\n",
       " 'reopened.',\n",
       " 'texts',\n",
       " 'ler',\n",
       " 'http://t.co/jCDd6SD6Qn',\n",
       " 'valley',\n",
       " 'tears',\n",
       " 'http://t.co/PyGKSSSCFR',\n",
       " 'Mafia',\n",
       " 'Office',\n",
       " 'lurkin',\n",
       " 'song',\n",
       " 'dominant',\n",
       " 'Humaza.',\n",
       " 'goodlook.Running',\n",
       " 'http://t.co/ZztbVjYPN1',\n",
       " 'Planned',\n",
       " 'Austin.',\n",
       " 'south\\x89Û_',\n",
       " 'solo',\n",
       " '#Indonesia',\n",
       " 'Fuddy',\n",
       " 'count',\n",
       " 'tr...',\n",
       " 'Became',\n",
       " 'http://t.co/gtHddzAvhg',\n",
       " 'http://t.co/TB8gZEMbXU',\n",
       " '#PieceOfMe',\n",
       " 'MUM',\n",
       " 'https://t.co/OAQtjawGxg',\n",
       " '6:08',\n",
       " 'CHPSRE:',\n",
       " 'Locksmithing-art',\n",
       " 'http://t.co/XlFi7ovhFJ',\n",
       " '@jozerphine',\n",
       " 'ultimatum',\n",
       " 'http://t.co/NVfKzv5FEx',\n",
       " '@beelieveDC',\n",
       " 'HALIFAX',\n",
       " 'derailment',\n",
       " 'crash.',\n",
       " 'CONNECTS',\n",
       " 'growing',\n",
       " 'programme',\n",
       " '5:15p',\n",
       " 'http://t.co/ajpbdCalew',\n",
       " 'http://t.co/u4bdy1W7d4',\n",
       " 'Tumblr:',\n",
       " 'nose',\n",
       " 'http://t.co/uCBfgIBFOR',\n",
       " '#sejorg',\n",
       " '#content',\n",
       " 'hair..but',\n",
       " 'Stout)',\n",
       " 'Effects',\n",
       " 'MaFireEMS:',\n",
       " '@PeterDutton_MP',\n",
       " 'upgraded',\n",
       " 'kindermorgan',\n",
       " 'MD',\n",
       " 'bee...',\n",
       " '#INCIDENT',\n",
       " 'https://t.co/EWnUnp8Hdo',\n",
       " 'Ass',\n",
       " '8:00PM',\n",
       " 'http://t.co/9q9Rk3fOf7',\n",
       " 'Greed',\n",
       " 'http://t.co/QVlxpyyyCd',\n",
       " 'KEEP',\n",
       " 'Kisii',\n",
       " 'freaking',\n",
       " 'Hazard',\n",
       " 'Drones',\n",
       " 'mama',\n",
       " 'a\\x89Û_',\n",
       " 'pone',\n",
       " 'v',\n",
       " 'cislady',\n",
       " 'http://t.co/ySpON4d6Qo',\n",
       " 'taint',\n",
       " 'Otherwise',\n",
       " 'artificial',\n",
       " 'dad(who',\n",
       " 'https://t.co/PC3h1NE4G0',\n",
       " 'http://t.co/SDmrzGErYX',\n",
       " 'http://t.co/hHZY3oqeLa',\n",
       " 'http://t.co/NXtWXJCAVh',\n",
       " 'Mesick:',\n",
       " '[In-game]',\n",
       " \"'Islamic\",\n",
       " 'Scourgue',\n",
       " 'returns',\n",
       " '#PPSellsBabyParts',\n",
       " 'ki',\n",
       " 'Freedom:',\n",
       " 'calif',\n",
       " 'Sr.',\n",
       " 'unawares',\n",
       " 'Frozen',\n",
       " 'Transporta...',\n",
       " '(Amsal',\n",
       " 'http://t.co/mkJO8x2dKo',\n",
       " 'TOP',\n",
       " 'http://t.co/S5F9FcOmp8',\n",
       " 'officials',\n",
       " 'impending',\n",
       " 'host:',\n",
       " '#cnbc',\n",
       " 'http://t.co/JlzK2HdeTG',\n",
       " 'Hurricane',\n",
       " 'w/heavenly',\n",
       " 'does',\n",
       " 'powerful!',\n",
       " 'promote',\n",
       " '#artectura',\n",
       " 'http://t.co/UJrX9kgawp',\n",
       " 'liability',\n",
       " 'Flying',\n",
       " 'http://t.co/YS3nMwWyVc',\n",
       " 'Tuffers',\n",
       " '@edsheeran',\n",
       " 'tho...',\n",
       " 'YA',\n",
       " 'Prompting',\n",
       " 'glove.',\n",
       " 'investigation',\n",
       " 'cc:',\n",
       " 'precedent.',\n",
       " 'incompetent.',\n",
       " 'Larger',\n",
       " 'Bank',\n",
       " 'uniform.',\n",
       " 'cousin',\n",
       " 'u',\n",
       " 'Supreme',\n",
       " 'x',\n",
       " 'Lifted',\n",
       " 'Heroine',\n",
       " 'MOVIES',\n",
       " 'Campus',\n",
       " 'psychologist',\n",
       " 'closely',\n",
       " '@CloydRivers',\n",
       " 'Blizzard',\n",
       " 'GTFO',\n",
       " 'flames...',\n",
       " 'courage',\n",
       " 'SNI',\n",
       " 'Dream',\n",
       " '#BB17.',\n",
       " '@Vickie627',\n",
       " 'me...',\n",
       " 'Just',\n",
       " 'Action',\n",
       " 'weights.',\n",
       " 'https://t.co/6Ce1vwOVHs',\n",
       " 'Breeder!',\n",
       " 'http://t.co/Zk69uGXMT8',\n",
       " 'Wheatley',\n",
       " 'seconds.',\n",
       " '@VinusTrip',\n",
       " '@afterShock_DeLo',\n",
       " 'drive-by',\n",
       " 'I-405',\n",
       " 'Boom',\n",
       " 'Career',\n",
       " \"'getting\",\n",
       " '@SoundCloud',\n",
       " 'unarmed',\n",
       " '@igmpj',\n",
       " 'practicing.',\n",
       " 'Sad.',\n",
       " 'Cross-border',\n",
       " '/r/Vaping101',\n",
       " '@AACE_org',\n",
       " 'x1402',\n",
       " 'life??????.',\n",
       " 'TITAN',\n",
       " '@keithboykin',\n",
       " 'Anti-Blight',\n",
       " 'PINER',\n",
       " \"aren't\",\n",
       " 'victim',\n",
       " 'Clearly',\n",
       " 'Two:',\n",
       " 'Crackdown',\n",
       " 'Escape',\n",
       " '24',\n",
       " 'fight?',\n",
       " 'https://t.co/pQHQ4JnZTT',\n",
       " 'cya',\n",
       " 'v...',\n",
       " '10:40',\n",
       " '#newsdict',\n",
       " 'damage.',\n",
       " 'Trends',\n",
       " 'song.',\n",
       " 'http://t.co/fQj0SqU3lG',\n",
       " 'Prone',\n",
       " 'attack..close',\n",
       " 'Newser',\n",
       " '02-06',\n",
       " 'http://t.co/Hz4lKFfC59',\n",
       " 'mueller',\n",
       " 'Sterling',\n",
       " 'wd',\n",
       " 'bot',\n",
       " 'http://t.co/WosYPVQUFI',\n",
       " 'http://t.co/Mphog0QDDN',\n",
       " 'is...',\n",
       " '@optich3cz',\n",
       " \"'twins'\",\n",
       " 'http://t.co/yqpAIjSa5g',\n",
       " 'http://t.co/vxeGCmMVBV',\n",
       " '@Captainn_Morgan',\n",
       " 'VIDEO]',\n",
       " '@gg_keeponrockin',\n",
       " '@DrFriedenCDC',\n",
       " 'UNWARRANTED',\n",
       " '@IndiGo6E',\n",
       " 'Mo\\x89Û_',\n",
       " '#News',\n",
       " 'Justin',\n",
       " 'http://t.co/ZYRZX6dfki',\n",
       " 'cracking',\n",
       " \"Aesthetic'\",\n",
       " 'makes',\n",
       " 'killing',\n",
       " 'http://t.co/ZUqgvJnEQA',\n",
       " 'http://t.co/MZ8VQXbKTs',\n",
       " '@hanna_brooksie',\n",
       " 'ohlordy',\n",
       " \"fine'\",\n",
       " 'spit',\n",
       " 'desolate.',\n",
       " 'http://t.co/l4wJHz4AJ6',\n",
       " '#summer2k15',\n",
       " '#computer',\n",
       " 'https://t.co/OHCx3y8l4s',\n",
       " 'broad',\n",
       " 'Volgagrad',\n",
       " '@ElijahMallari',\n",
       " 'nice.',\n",
       " 'https://t.co/YX1UKbmTqB',\n",
       " 'foreign',\n",
       " 'http://t.co/dDR0zjXVQN',\n",
       " 'ask',\n",
       " 's2g',\n",
       " 'Burns',\n",
       " 'lateral',\n",
       " 'Firefighter',\n",
       " 'http://t.co/l7BJSq0Y2o',\n",
       " 'http://t.co/vn0acCF6D4',\n",
       " 'soz',\n",
       " 'http://t.co/xcGzc45gys',\n",
       " 'G+:',\n",
       " 'Updates:',\n",
       " 'essenceOfMe',\n",
       " '#vaxshill',\n",
       " 'twitch',\n",
       " 'A2&gt;Hanover',\n",
       " 'Lansdowne',\n",
       " 'currently',\n",
       " 'half-railed?',\n",
       " 'Feat.',\n",
       " 'http://t.co/fqcDPhccg7',\n",
       " 'Austin',\n",
       " '@stfxuniversity',\n",
       " 'Yep.',\n",
       " 'grabbed',\n",
       " 'BUILDINGS',\n",
       " 'Korea.',\n",
       " 'http://t.co/dAn0Gkx28l',\n",
       " 'Post',\n",
       " 'heroes...',\n",
       " 'blessed!',\n",
       " 'http://t.co/VMf5LnxVzC',\n",
       " 'phandom',\n",
       " 'recently',\n",
       " 'marinading',\n",
       " 'http://t.co/GeI58Vhbw6',\n",
       " 'joy',\n",
       " 'fence.',\n",
       " 'club',\n",
       " 'http://t.co/HQsU8LWltH',\n",
       " 'http://t.co/RVczMimfVx',\n",
       " 'ruled',\n",
       " 'rude',\n",
       " 'box.',\n",
       " 'http://t.co/RcqacN91bE',\n",
       " 'horror',\n",
       " \"Priority'\",\n",
       " \"'I'm\",\n",
       " 'Spartans',\n",
       " 'http://t.co/d5h4jif1y3',\n",
       " 'Saturday!',\n",
       " 'http://t.co/vVPLFQv58P',\n",
       " 'He',\n",
       " 'lookg',\n",
       " 'since.',\n",
       " 'Forbath',\n",
       " 'Fukushima',\n",
       " 'http://t.co/E3L1JqjH2u',\n",
       " 'http://t.co/7old5MJWph',\n",
       " '@AP',\n",
       " 'http://t.co/RUjV4VPnBV',\n",
       " 'mega',\n",
       " 'ablaze.',\n",
       " 'http://t.co/AQcSUSqbDy',\n",
       " 'Croat',\n",
       " 't/the',\n",
       " 'Volcano',\n",
       " 'StephenSCIFI:',\n",
       " 'Soundtrack',\n",
       " 'mail',\n",
       " 'audiences.',\n",
       " '#Wimbledon',\n",
       " 'Slowly',\n",
       " 'RIGHT',\n",
       " 'gave',\n",
       " 'Freak',\n",
       " '-Lou',\n",
       " 'upcoming',\n",
       " 'Cherry',\n",
       " 'http://t.co/B8iWRdxcm0',\n",
       " 'units',\n",
       " 'fatalities.',\n",
       " 'http://t.co/DXfqOu4kT2',\n",
       " 'mosque',\n",
       " '@mcnabbychic',\n",
       " 'kissing',\n",
       " 'Lit',\n",
       " 'burning:',\n",
       " 'fo...',\n",
       " 'tita-dom:',\n",
       " 'theater:',\n",
       " 'angers',\n",
       " 'Buckley',\n",
       " '@BldrCOSheriff',\n",
       " 'Cabin',\n",
       " 'majority',\n",
       " 'http://t.co/iPHaZV47g7',\n",
       " 'http://t.co/k14q8cHWKp',\n",
       " '@niamhosullivanx',\n",
       " 'Legal',\n",
       " \"'alarmed'\",\n",
       " '@likeavillasboas',\n",
       " 'yes;',\n",
       " 'fold',\n",
       " 'http://t.co/zY3hpdJNwg',\n",
       " 'Finds',\n",
       " 'laughing',\n",
       " 'Briliantly',\n",
       " 'PHONE',\n",
       " 'Editor',\n",
       " 'treasure-house',\n",
       " 'diasporas',\n",
       " 'OUN',\n",
       " '@EyTay',\n",
       " 'nope!!',\n",
       " 'injury.',\n",
       " 'http://t.co/FgDEh56PLO',\n",
       " '#cogXbox',\n",
       " '#Blowltan',\n",
       " 'http://t.co/7nU7pRxeul',\n",
       " '#solicitor',\n",
       " 'quantum',\n",
       " 'heroin',\n",
       " 'incitement',\n",
       " 'http://t.co/nn6Y0fD3l0',\n",
       " 'sucks.',\n",
       " 'Women',\n",
       " 'aboard',\n",
       " '@comcastcares',\n",
       " 'Incase',\n",
       " 'cave',\n",
       " 'Boss',\n",
       " '#diet',\n",
       " 'Nice',\n",
       " '7p.',\n",
       " '#RemyMarcel',\n",
       " '@Hughes1128',\n",
       " 'FWD:',\n",
       " 'power...wow',\n",
       " 'bck',\n",
       " '....bout',\n",
       " 'fav.',\n",
       " 'NEWS',\n",
       " '@stury',\n",
       " 'ducks.',\n",
       " 'recycling',\n",
       " '#destruction',\n",
       " 'w...',\n",
       " '4pm',\n",
       " 'u2',\n",
       " 'Senator',\n",
       " 'Paints',\n",
       " 'stock:',\n",
       " 'Zach',\n",
       " 'heels',\n",
       " 'swear',\n",
       " '4.5%',\n",
       " '@Arovolturi3000',\n",
       " 'U',\n",
       " 'sophistication',\n",
       " 'gmtTy',\n",
       " '#fat',\n",
       " 'ight',\n",
       " '@Jason_Floyd',\n",
       " '@Tim_A_Roberts',\n",
       " 'dougkessler',\n",
       " 'appalling:',\n",
       " 'Daughter',\n",
       " '@Judson1360',\n",
       " 'p.m.',\n",
       " 'http://t.co/X5YEUYLT1X',\n",
       " 'Kurt',\n",
       " 'Hating',\n",
       " 'http://t.co/a3RGQuCUgo',\n",
       " 'Tanzania',\n",
       " '#Clinton',\n",
       " 'kurtkamka:',\n",
       " 'http://t.co/k9FBtcCU58',\n",
       " 'impacting',\n",
       " '@gilmanrocks7',\n",
       " 'that?!',\n",
       " '@SophieWisey',\n",
       " 'hirochii0:',\n",
       " '@attackonstiles',\n",
       " 'Displaced',\n",
       " 'http://t.co/GgnbVZoHWu',\n",
       " '#usa',\n",
       " 'reading;',\n",
       " 'driving.\\x89Û\\x9d',\n",
       " 'http://t.co/zqrcptLrUM',\n",
       " 'http://t.co/ubVEVUuAch',\n",
       " 'intersections',\n",
       " 'action!',\n",
       " '27',\n",
       " 'container',\n",
       " 'LeedStraiF',\n",
       " \"Women's\",\n",
       " 'years*',\n",
       " '@ResignInShame',\n",
       " 'Retail',\n",
       " 'Northland',\n",
       " 'http://t.co/kBe91aRCdw',\n",
       " 'assault',\n",
       " 'http://t.co/ONxhKfHn2a',\n",
       " 'jurors',\n",
       " 'Like!',\n",
       " 'Clico',\n",
       " '\\x89Ûª93',\n",
       " 'tea',\n",
       " '(thus',\n",
       " 'WC',\n",
       " 'Rocket',\n",
       " 'Trains',\n",
       " '#UTFire',\n",
       " 'states',\n",
       " 'bottom',\n",
       " '#1-1ST',\n",
       " 'folks',\n",
       " 'secret',\n",
       " \"memory'\",\n",
       " 'S\\x89ÛªArabia',\n",
       " 'http://t.co/Bgy4i47j70',\n",
       " '#education',\n",
       " 'rifles',\n",
       " 'greinke',\n",
       " 'HamptonRoadsFor.me',\n",
       " 'Media:',\n",
       " 'Helping',\n",
       " 'WEAPON',\n",
       " '@durrellb',\n",
       " 'Then',\n",
       " 'Skylanders',\n",
       " 'Bard',\n",
       " 'recalls',\n",
       " 'been!',\n",
       " 'Differently',\n",
       " 'tonight?!',\n",
       " 'Explode',\n",
       " '@ShekharGupta',\n",
       " 'http://t.co/9Jxb3rx8mF',\n",
       " 'inequality',\n",
       " 'http://t.co/dVONWIv3l1',\n",
       " 'CAREER',\n",
       " 'Christ',\n",
       " 'HAPPINESS',\n",
       " 'Tale',\n",
       " 'Charger',\n",
       " 'buck',\n",
       " 'Ocean',\n",
       " 'plane',\n",
       " 'http://t.co/aPVLH7hj1O',\n",
       " 'https://t.co/WtGGqS5gEh',\n",
       " 'technique.',\n",
       " 'manifestation',\n",
       " '#MyLifeStory',\n",
       " 'Failure',\n",
       " 'guide',\n",
       " 'hype',\n",
       " 'PawSox',\n",
       " '70...&amp;',\n",
       " 'http://t.co/0TSlQjOKvh',\n",
       " 'Tryna',\n",
       " 'Entire',\n",
       " 'AK:',\n",
       " '#blockchain',\n",
       " '@pageparkescorp',\n",
       " 'http://t.co/KcTiGYMahl',\n",
       " 'fifth',\n",
       " 'http://t.co/tCXxHdJAs6',\n",
       " 'line',\n",
       " '#tattoo',\n",
       " 'WN',\n",
       " \"possible.'\",\n",
       " 'Motorcyclist',\n",
       " '&amp;story',\n",
       " '@Rubi_',\n",
       " '23:40:21',\n",
       " 'scam',\n",
       " 'http://t.co/JlWGshYY3N',\n",
       " '#VideoGame',\n",
       " 'beard',\n",
       " 'Tennessee',\n",
       " '#CLIMATE',\n",
       " 'http://t.co/ACZRUOrYtD',\n",
       " '@_chelsdelong12',\n",
       " 'ARA',\n",
       " 'calorie',\n",
       " 'http://t.co/zaRBwep9LD',\n",
       " 'guild',\n",
       " 'WHELEN',\n",
       " 'justified',\n",
       " '#food',\n",
       " 'Errrr',\n",
       " '@bigburgerboi55',\n",
       " 'Lincoln',\n",
       " 'http://t.co/SAkORGdqUL',\n",
       " 'murderer?',\n",
       " 'SIBLING',\n",
       " 'She\\x89Ûªs',\n",
       " 'Wall\\x89Û\\x9d.',\n",
       " '8/10',\n",
       " 'recently.',\n",
       " 'Rosalie',\n",
       " 'http://t.co/TH9YwBbeet',\n",
       " 'want!',\n",
       " 'Josie',\n",
       " 'ma...',\n",
       " 'nine-year-old',\n",
       " 'surge',\n",
       " 'Nueva',\n",
       " 'http://t.co/9asc1hhFNJ',\n",
       " 'https://t.co/zv60cHjclF',\n",
       " 'nudes',\n",
       " 'kou',\n",
       " 'Hobbit:',\n",
       " '[2]',\n",
       " 'lonelyness',\n",
       " 'nostalgia',\n",
       " 'Veld',\n",
       " 'Cash',\n",
       " \"Legionnaires'...\",\n",
       " 'idc',\n",
       " 'Day.',\n",
       " 'multi',\n",
       " 'pleb',\n",
       " 'link:',\n",
       " 'hush',\n",
       " 'http://t.co/bP597YDs2b',\n",
       " 'http://t.co/6mF7eyZOAw',\n",
       " 'Mississippi',\n",
       " 'congratulations',\n",
       " 'vanished',\n",
       " '#man',\n",
       " 'The',\n",
       " 'soon!',\n",
       " 'SkanndTyagi:',\n",
       " '@_AnimalAdvocate',\n",
       " 'purified.',\n",
       " 'remorse',\n",
       " '@InfiniteGrace7',\n",
       " 'sons',\n",
       " 'News@',\n",
       " 'wins??',\n",
       " 'plan.',\n",
       " 'happy.',\n",
       " 'diamond',\n",
       " 'diverts',\n",
       " '#GRupdates',\n",
       " 'Zurich',\n",
       " 'boys',\n",
       " 'Unaware',\n",
       " 'bleeding??',\n",
       " 'Rogue',\n",
       " 'argsuppose',\n",
       " 'http://t.co/m203UL6o7p',\n",
       " 'Kraft',\n",
       " 'tier/',\n",
       " 'infantryman',\n",
       " '#Ices\\x89Û_',\n",
       " 'fighting',\n",
       " '#Helsinki\\x89Û_',\n",
       " 'Flaws',\n",
       " 'BEHIND',\n",
       " 'Hijacker-Turned-SAT-Tutor',\n",
       " 'mask.',\n",
       " 'respects',\n",
       " '#TNN:',\n",
       " 'Cafe.....awful',\n",
       " 'erodes',\n",
       " 'Mizuta...',\n",
       " 'Strikers',\n",
       " \"'Three\",\n",
       " 'Yeahs',\n",
       " 'Manitou,',\n",
       " 'ITUNES',\n",
       " 'http://t.co/Nh5pkFBfqm',\n",
       " 'man.',\n",
       " 'FILM',\n",
       " 'http://t.co/0f8XA4Ih1U',\n",
       " '#TRC',\n",
       " 'Hollywood?',\n",
       " 'Likely',\n",
       " 'http://t.co/DlP8kPkt2k',\n",
       " 'hogging',\n",
       " 'Least',\n",
       " \"WOMEN'S\",\n",
       " \"'historic'\",\n",
       " 'inundated',\n",
       " '24:1',\n",
       " 'http://t.co/CWGCciw3V6',\n",
       " '[TREMOR',\n",
       " 'rubbin',\n",
       " 'journeys',\n",
       " 'http://t.co/DEfJ7XeKgX',\n",
       " 'Chattanooga',\n",
       " 'http://t.co/M9YdA5k6jf',\n",
       " 'Beware',\n",
       " 'Saturn',\n",
       " '@YahooFinance#Hope',\n",
       " 'http://t.co/4ou8s82HxJ',\n",
       " 'Inj',\n",
       " \"they're\",\n",
       " 'YOU',\n",
       " '@alextucker',\n",
       " 'http://t.co/c1nJpLi5oR',\n",
       " \"PRESENT)'\",\n",
       " 'LITERALLY',\n",
       " 'Make',\n",
       " 'days?',\n",
       " '@Pam_Palmater',\n",
       " '10km',\n",
       " 'trick',\n",
       " 'Moments)',\n",
       " 'ouch',\n",
       " 'Control',\n",
       " 'Sparks',\n",
       " '@Annealiz1',\n",
       " '@PhilipDuncan',\n",
       " 'Dozens',\n",
       " 'Harry',\n",
       " '@iamHorsefly',\n",
       " 'Finna',\n",
       " 'OPP.',\n",
       " 'thesensualeye:',\n",
       " \"'Some\",\n",
       " '@FiendNikki',\n",
       " \"'Get\",\n",
       " 'Salvation',\n",
       " '(SJ',\n",
       " 'adventures',\n",
       " 'Hazard/Willian',\n",
       " \"'Crash\",\n",
       " \"'Argentina':\",\n",
       " 'Work',\n",
       " '#prepper',\n",
       " 'soon.',\n",
       " 'EYES',\n",
       " 'chicken',\n",
       " 'died....',\n",
       " 'Kalle',\n",
       " 'up:',\n",
       " \"California's\",\n",
       " 'nuclear',\n",
       " 'Greedy',\n",
       " 'ah',\n",
       " 'tonight\\x89Ûªs',\n",
       " 'on:',\n",
       " 'put',\n",
       " 'happening!',\n",
       " 'West',\n",
       " '\\x89Û÷ALLOOSH',\n",
       " 'http://t.co/nmAUMYdKe1',\n",
       " 'Roger',\n",
       " 'Shed',\n",
       " 'http://t.co/oi6CmAGASi',\n",
       " 'http://t.co/jGdlX4Faw8',\n",
       " \"Iger's\",\n",
       " 'http://t.co/cf9e6TU3g7',\n",
       " 'resort',\n",
       " 'H20',\n",
       " 'inner',\n",
       " 'slow',\n",
       " '90-100.',\n",
       " 'peeps!!',\n",
       " 'dqSVYusY',\n",
       " 'No.2',\n",
       " \"'demolish\",\n",
       " 'healed!!!',\n",
       " 'lightning*',\n",
       " 'days',\n",
       " 'British',\n",
       " 'water??',\n",
       " 'Zergele',\n",
       " 'until?',\n",
       " 'Foothill',\n",
       " 'totaling',\n",
       " 'Tantrums',\n",
       " 'bts',\n",
       " 'against',\n",
       " 'Utd',\n",
       " 'Boise',\n",
       " 'lesson..',\n",
       " 'mockery',\n",
       " 'https://t.co/vwz3vZpmfb',\n",
       " 'fires?',\n",
       " 'http://t.co/dpgdnaoY4p',\n",
       " 'https://t.co/of3td6DGLb',\n",
       " \"Casualty'.\",\n",
       " 'fondness',\n",
       " 'http://t.co/9z9HsmiaVD',\n",
       " 'Imagini',\n",
       " 'http://t.co/UcI8stQUg1',\n",
       " 'SubsD...',\n",
       " '@DannyRaynard',\n",
       " '@kendra_leigh13',\n",
       " 'darkest',\n",
       " 'cold',\n",
       " 'hes',\n",
       " 'https://t.co/ZhJlfLBHZL',\n",
       " 'swallowed.',\n",
       " 'nuff',\n",
       " '#KRO',\n",
       " 'students',\n",
       " 'kids',\n",
       " 'http://t.co/2SZ7oKjRXi',\n",
       " '@adndotcom',\n",
       " 'FANGIRLING',\n",
       " 'lasted',\n",
       " '#FreeALLFour',\n",
       " 'http://t.co/MgR809yc5a',\n",
       " 'boxer',\n",
       " 'http://t.co/nJMiDySXoF',\n",
       " 'Penneys',\n",
       " 'beef',\n",
       " 'Winston',\n",
       " 'oppa',\n",
       " 'http://t.co/QymAlttvZp',\n",
       " 'dept.',\n",
       " 'cartridges...',\n",
       " \"Thursday'\",\n",
       " 'Dajaal?',\n",
       " 'browsing',\n",
       " '@carneross',\n",
       " 'http://t.co/hylMo0WgFI',\n",
       " 'http://t.co/3bRme6Sn4t',\n",
       " 'Hardside',\n",
       " 'call.',\n",
       " 'journalism:',\n",
       " 'OVER!!!',\n",
       " 'Grow',\n",
       " 'NRC_MiddleEast:',\n",
       " 'cultural',\n",
       " 'Original',\n",
       " 'JAPANESE',\n",
       " 'flames!',\n",
       " 'carried',\n",
       " 'SOOOO',\n",
       " 'Parliamentary',\n",
       " 'bruh?',\n",
       " \"'Detonate'\",\n",
       " 'ultimate',\n",
       " 'WORD',\n",
       " 'http://t.co/lY8x7rqbwN',\n",
       " 'LIKE',\n",
       " 'investigation:',\n",
       " 'paeds',\n",
       " \"Higuain's\",\n",
       " 'workplace',\n",
       " 'http://t.co/wHOc7LHb5F',\n",
       " 'court\\x89Ûªs',\n",
       " 'http://t.co/zEVakJaPcz',\n",
       " '-__-',\n",
       " 'Mystery',\n",
       " 'info',\n",
       " 'Signed',\n",
       " 'amazing',\n",
       " 'entrances',\n",
       " 'Sadly',\n",
       " '#mercados',\n",
       " '@_301DC',\n",
       " 'obliterated.',\n",
       " '@kelworldpeace',\n",
       " 'pride',\n",
       " 'Inspiring!',\n",
       " 'xavier',\n",
       " 'enemies!',\n",
       " '#HSE',\n",
       " 'right!',\n",
       " 'modest.',\n",
       " 'southwest',\n",
       " 'cars.',\n",
       " 'skill',\n",
       " '@realdonaldtrump',\n",
       " 'live',\n",
       " 'receiving',\n",
       " 'http://t.co/zM6VcZqvWk',\n",
       " 'http://t.co/6FYnerMUsG',\n",
       " 'subject',\n",
       " '*drools*',\n",
       " 'rooms',\n",
       " 'expander',\n",
       " 'Sharif',\n",
       " 'ferries',\n",
       " 'http://t.co/I9dSPDKrUK',\n",
       " 'rescind',\n",
       " 'Bob',\n",
       " 'Shock',\n",
       " 'landslide',\n",
       " 'firey',\n",
       " 'LINK:',\n",
       " 'Bukidnon:',\n",
       " '@tonycottee1986',\n",
       " 'http://t.co/L3w8miPvnT',\n",
       " 'horses',\n",
       " 'M.O.P.?',\n",
       " 'http://t.co/HaShGQAFic',\n",
       " 'intelligence.',\n",
       " '#golf',\n",
       " 'plz',\n",
       " 'Supply',\n",
       " 'dealbreaker',\n",
       " 'w/soaring',\n",
       " 'O',\n",
       " 'Outbreak?',\n",
       " 'Yosemite',\n",
       " 'M4.',\n",
       " 'day-to-day:',\n",
       " 'evolve.',\n",
       " '##youtube',\n",
       " '513',\n",
       " 'dark.',\n",
       " 'all!!!',\n",
       " 'possible',\n",
       " 'http://t.co/eRJ7YANjXm',\n",
       " 'catastrophic-fallen-angel:',\n",
       " 'DAMAGE;3460',\n",
       " 'Wesley',\n",
       " 'Natalie',\n",
       " 'docked',\n",
       " 'Dress',\n",
       " 'unlocking',\n",
       " 'G20',\n",
       " 'Very',\n",
       " 'idm',\n",
       " 'caution',\n",
       " 'http://t.co/xXOuPfy8nQ',\n",
       " 'soudelor.',\n",
       " 'christie',\n",
       " 'http://t.co/iap4LwvqsW',\n",
       " 'trigger',\n",
       " 'bae',\n",
       " '08/02/15:',\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_all = voc_dis.union(voc_non)\n",
    "voc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-44f8e4ecfb2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "from nltk import *\n",
    "\n",
    "train_df['text'].vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_count = len(voc_all)\n",
    "total_dis_count = len(voc_dis)\n",
    "total_non_count = len(voc_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31924 16150 20560\n"
     ]
    }
   ],
   "source": [
    "print(total_vocab_count, total_dis_count, total_non_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencyDist = nltk.ConditionalFreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalProbDist with 0 conditions>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilityDist = nltk.ConditionalProbDist(frequencyDist, nltk.LaplaceProbDist, bins=frequencyDist.N())\n",
    "probabilityDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean keywords for better idea of trends\n",
    "def clean_keywords(keyword):\n",
    "    cleaned = re.sub(r'%20', ' ', keyword)\n",
    "    return cleaned\n",
    "def remove_accents(keyword):\n",
    "    cleaned = unidecode.unidecode(keyword)\n",
    "    return cleaned\n",
    "def remove_punctuation(keyword):\n",
    "    cleaned = re.sub(r\"[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n -' ]\",\" \",keyword)\n",
    "    return cleaned\n",
    "#train_df['keyword'].apply(clean_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    @dicehateme @PuppyShogun This makes sense. Pap...\n",
       "6351    '@CatoInstitute: The causes of federal failure...\n",
       "3443    Well as I was chaning an iPad screen it fuckin...\n",
       "7164    the war on drugs has turned the U.S. into a WA...\n",
       "7037    Obama Declares Disaster for Typhoon-Devastated...\n",
       "                              ...                        \n",
       "5226    @Eganator2000 There aren't many Obliteration s...\n",
       "5390    just had a panic attack bc I don't have enough...\n",
       "860     Omron HEM-712C Automatic Blood Pressure Monito...\n",
       "7603    Officials say a quarantine is in place at an A...\n",
       "7270    I moved to England five years ago today. What ...\n",
       "Name: text, Length: 5709, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'@CatoInstitute: The causes of federal failure are deeply structural and they will not be easily solved: http://t.co/H2XcaX4jbU'\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = X_train.iloc[1]\n",
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\",\n",
       " '@',\n",
       " 'CatoInstitute',\n",
       " ':',\n",
       " 'The',\n",
       " 'causes',\n",
       " 'of',\n",
       " 'federal',\n",
       " 'failure',\n",
       " 'are',\n",
       " 'deeply',\n",
       " 'structural',\n",
       " 'and',\n",
       " 'they',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'easily',\n",
       " 'solved',\n",
       " ':',\n",
       " 'http',\n",
       " ':',\n",
       " '//t.co/H2XcaX4jbU',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the cleaned tweets data:\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_sample_tweet = word_tokenize(train_sample)\n",
    "tokenized_sample_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the data:\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)\n",
    "\n",
    "X_train_tokenized = X_train.copy()\n",
    "X_test_tokenized = X_test.copy()\n",
    "X_train_tokenized = X_train.apply(tokenizer.tokenize)\n",
    "X_test_tokenized = X_test.apply(tokenizer.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    @dicehateme @PuppyShogun This makes sense. Pap...\n",
       "6351    '@CatoInstitute: The causes of federal failure...\n",
       "3443    Well as I was chaning an iPad screen it fuckin...\n",
       "7164    the war on drugs has turned the U.S. into a WA...\n",
       "7037    Obama Declares Disaster for Typhoon-Devastated...\n",
       "                              ...                        \n",
       "5226    @Eganator2000 There aren't many Obliteration s...\n",
       "5390    just had a panic attack bc I don't have enough...\n",
       "860     Omron HEM-712C Automatic Blood Pressure Monito...\n",
       "7603    Officials say a quarantine is in place at an A...\n",
       "7270    I moved to England five years ago today. What ...\n",
       "Name: text, Length: 5709, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Just\n",
       "0        happened\n",
       "0        terrible\n",
       "0             car\n",
       "0           crash\n",
       "          ...    \n",
       "3262          its\n",
       "3262    Municipal\n",
       "3262    Emergency\n",
       "3262         Plan\n",
       "3262     yycstorm\n",
       "Name: text_tokenized, Length: 50940, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "train_df[\"text_tokenized\"] = train_df[\"text\"].apply(tokenizer.tokenize)\n",
    "test_df[\"text_tokenized\"] = test_df[\"text\"].apply(tokenizer.tokenize)\n",
    "\n",
    "train_df[\"text_tokenized\"].explode()\n",
    "test_df[\"text_tokenized\"].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def visualize_top_10(freq_dist, title):\n",
    "\n",
    "    # Extract data for plotting\n",
    "    top_10 = list(zip(*freq_dist.most_common(10)))\n",
    "    tokens = top_10[0]\n",
    "    counts = top_10[1]\n",
    "\n",
    "    # Set up plot and plot data\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(tokens, counts)\n",
    "\n",
    "    # Customize plot appearance\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    \n",
    "#visualize_top_10(example_freq_dist, \"Top 10 Word Frequency for Example Tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_freq_dist = FreqDist(train_df[\"text_tokenized\"].explode())\n",
    "visualize_top_10(train_freq_dist, \"Top 10 Word Frequency for train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_freq_dist = FreqDist(test_df[\"text_tokenized\"].explode())\n",
    "visualize_top_10(test_freq_dist, \"Top 10 Word Frequency for test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  keyword  location  target  text  text_tokenized\n",
       "0  1.0      0.0       0.0     0.0   0.0             0.0\n",
       "1  0.0      1.0       0.0     0.0   0.0             0.0\n",
       "2  0.0      0.0       1.0     0.0   0.0             0.0\n",
       "3  0.0      0.0       0.0     0.0   1.0             0.0\n",
       "4  0.0      0.0       0.0     1.0   0.0             0.0\n",
       "5  0.0      0.0       0.0     0.0   0.0             1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is this cell necessary?\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10)\n",
    "#max_features=None\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n",
    "X_test_vectorized = tfidf.transform(X_test)\n",
    "\n",
    "# Which do I use?? The whole train_df or just X_train?\n",
    "\n",
    "train_df_vectorized = tfidf.fit_transform(train_df)\n",
    "test_df_vectorized = tfidf.transform(test_df)\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(train_df_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    [dicehateme, PuppyShogun, This, makes, sense, ...\n",
       "6351    [CatoInstitute, The, causes, of, federal, fail...\n",
       "3443    [Well, as, was, chaning, an, iPad, screen, it,...\n",
       "7164    [the, war, on, drugs, has, turned, the, into, ...\n",
       "7037    [Obama, Declares, Disaster, for, Typhoon, Deva...\n",
       "                              ...                        \n",
       "5226    [Eganator2000, There, aren, many, Obliteration...\n",
       "5390    [just, had, panic, attack, bc, don, have, enou...\n",
       "860     [Omron, HEM, 712C, Automatic, Blood, Pressure,...\n",
       "7603    [Officials, say, quarantine, is, in, place, at...\n",
       "7270    [moved, to, England, five, years, ago, today, ...\n",
       "Name: text, Length: 5709, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Madhya',\n",
       " 'Pradesh',\n",
       " 'Train',\n",
       " 'Derailment',\n",
       " 'Village',\n",
       " 'Youth',\n",
       " 'Saved',\n",
       " 'Many',\n",
       " 'Lives']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized.iloc[70][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Word Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try count vectorization, then tf-idf ?\n",
    "# Creating a 'bag of words'\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer(max_features=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>co</th>\n",
       "      <th>for</th>\n",
       "      <th>http</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5709 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      and  co  for  http  in  is  of  the  to  you\n",
       "0       1   0    0     0   0   0   0    0   1    0\n",
       "1       1   1    0     1   0   0   1    1   0    0\n",
       "2       1   0    0     0   0   1   0    1   1    0\n",
       "3       0   0    0     0   0   0   0    2   0    0\n",
       "4       0   0    1     0   0   0   0    0   0    0\n",
       "...   ...  ..  ...   ...  ..  ..  ..  ...  ..  ...\n",
       "5704    0   0    0     0   0   0   0    0   1    0\n",
       "5705    1   0    1     0   0   0   0    1   1    0\n",
       "5706    1   2    0     2   0   0   0    0   0    0\n",
       "5707    0   1    0     1   1   1   0    0   0    0\n",
       "5708    0   1    0     1   0   0   1    0   1    0\n",
       "\n",
       "[5709 rows x 10 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count_vectorized = count_vec.fit_transform(X_train)\n",
    "X_test_count_vectorized = count_vec.transform(X_test)\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_count_vectorized, columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>.</th>\n",
       "      <th>:</th>\n",
       "      <th>?</th>\n",
       "      <th>@</th>\n",
       "      <th>a</th>\n",
       "      <th>http</th>\n",
       "      <th>in</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362669</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.746706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346645</td>\n",
       "      <td>0.403974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785442</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521150</td>\n",
       "      <td>0.607338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825513</td>\n",
       "      <td>0.291642</td>\n",
       "      <td>0.406374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480049</td>\n",
       "      <td>0.324776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.512819</td>\n",
       "      <td>0.362343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5709 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        #         .         :    ?         @         a      http        in  \\\n",
       "0     0.0  0.660024  0.000000  0.0  0.660956  0.000000  0.000000  0.000000   \n",
       "1     0.0  0.000000  0.792802  0.0  0.391163  0.000000  0.294835  0.000000   \n",
       "2     0.0  0.746706  0.000000  0.0  0.000000  0.398839  0.000000  0.000000   \n",
       "3     0.0  0.422978  0.000000  0.0  0.000000  0.451852  0.000000  0.000000   \n",
       "4     0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "...   ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "5704  0.0  0.000000  0.417074  0.0  0.617344  0.000000  0.000000  0.000000   \n",
       "5705  0.0  0.000000  0.000000  0.0  0.000000  0.599619  0.000000  0.000000   \n",
       "5706  0.0  0.000000  0.667451  0.0  0.000000  0.000000  0.744654  0.000000   \n",
       "5707  0.0  0.000000  0.261405  0.0  0.000000  0.825513  0.291642  0.406374   \n",
       "5708  0.0  0.480049  0.324776  0.0  0.000000  0.512819  0.362343  0.000000   \n",
       "\n",
       "           the        to  \n",
       "0     0.000000  0.357079  \n",
       "1     0.362669  0.000000  \n",
       "2     0.346645  0.403974  \n",
       "3     0.785442  0.000000  \n",
       "4     0.000000  0.000000  \n",
       "...        ...       ...  \n",
       "5704  0.000000  0.667035  \n",
       "5705  0.521150  0.607338  \n",
       "5706  0.000000  0.000000  \n",
       "5707  0.000000  0.000000  \n",
       "5708  0.000000  0.519421  \n",
       "\n",
       "[5709 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10, tokenizer=word_tokenize)\n",
    "\n",
    "\n",
    "X_train_vectorized1 = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Visually inspect the vectorized data\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized1, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Building a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8035714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84      1091\n",
      "           1       0.81      0.70      0.75       813\n",
      "\n",
      "    accuracy                           0.80      1904\n",
      "   macro avg       0.81      0.79      0.80      1904\n",
      "weighted avg       0.80      0.80      0.80      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "baseline_model = Pipeline([('vect', CountVectorizer(tokenizer=word_tokenize)),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_features\": [None ,10, 100, 200],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator TfidfVectorizer(max_features=10,\n                tokenizer=<function word_tokenize at 0x7fe75eab99d0>) does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-fea795e52f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0m\u001b[1;32m    655\u001b[0m             self.estimator, scoring=self.scoring)\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    474\u001b[0m                                                           str):\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator TfidfVectorizer(max_features=10,\n                tokenizer=<function word_tokenize at 0x7fe75eab99d0>) does not."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(tfidf , params, cv=3, return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train, score='f1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7972689075630253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      1091\n",
      "           1       0.88      0.61      0.72       813\n",
      "\n",
      "    accuracy                           0.80      1904\n",
      "   macro avg       0.82      0.77      0.78      1904\n",
      "weighted avg       0.81      0.80      0.79      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with TF-IDF Vectorizer instead of CountVectorizer, added tfidfTransformer\n",
    "model2 = Pipeline([('vect', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "                   #('tfidf', TfidfTransformer()),\n",
    "                   ('clf', MultinomialNB())\n",
    "                   #('tokenizer', RegexpTokenizer(basic_token_pattern))\n",
    "                  ])\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "#from nltk.lm import Laplace\n",
    "#model2 = Laplace(1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred2, y_test))\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch??\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB() )\n",
    "])\n",
    "\n",
    "# Apparently the only hyperparams for MultinomialNB, but what do they mean?\n",
    "# What about max_features?\n",
    "parameters = {\n",
    "    'alpha': (1, 2, 3),\n",
    "    'class_prior': (),\n",
    "    'fit_prior': ()\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'reg__alpha': (0.00001, 0.000001),\n",
    "    #\"max_features\": [None ,10, 100, 200],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'class_prior', 'fit_prior'])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter max_features for estimator Pipeline(steps=[('vect', TfidfVectorizer()), ('tfidf', TfidfTransformer()),\n                ('clf', MultinomialNB())]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-231b374c92ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[1;32m    250\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter max_features for estimator Pipeline(steps=[('vect', TfidfVectorizer()), ('tfidf', TfidfTransformer()),\n                ('clf', MultinomialNB())]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    dicehateme puppyshogun makes sense paper beats...\n",
       "6351    ' catoinstitute causes federal failure deeply ...\n",
       "3443    well chaning ipad screen fucking exploded glas...\n",
       "7164                          war drugs turned u war zone\n",
       "7037    obama declares disaster typhoon devastated saipan\n",
       "5159    according prophecy also cnn mac tablet complet...\n",
       "1010           body bagged rt lac drake body bagging meek\n",
       "5070        connorfranta askconnor natural disaster would\n",
       "2069    soapscoop need confirm ross dead cause dont tr...\n",
       "931     libraryeliza get taylorswift 'bump' approval p...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords, punctuation, numbers, and bad characters \n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "no_bad_chars = re.compile('[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n - ]')\n",
    "no_nums = re.compile('[\\d-]')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = no_bad_chars.sub(' ', text) \n",
    "    text = no_nums.sub('', text) \n",
    "    \n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords_list)\n",
    "    return text\n",
    "    \n",
    "\n",
    "X_train_cleaned = X_train.apply(clean_text)\n",
    "X_test_cleaned = X_test.apply(clean_text)\n",
    "X_train_cleaned.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2fe191bcb84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdisasters_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnon_disasters_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "# see vocab for cleaned data\n",
    "train_df_cleaned = train_df['text'].apply(clean_text)\n",
    "\n",
    "disasters_cleaned = train_df_cleaned[train_df_cleaned['target']==1]\n",
    "non_disasters_cleaned = train_df_cleaned[train_df_cleaned['target']==0]\n",
    "\n",
    "voc_dis_cleaned = vocab_maker(disasters_cleaned['text'])\n",
    "voc_non_cleaned = vocab_maker(non_disasters_cleaned['text'])\n",
    "\n",
    "voc_all_cleaned = voc_dis_cleaned.union(voc_non_cleaned)\n",
    "voc_all_cleaned\n",
    "\n",
    "total_vocab_count_cl = len(voc_all_cleaned)\n",
    "total_dis_count_cl = len(voc_dis_cleaned)\n",
    "total_non_count_cl = len(voc_non_cleaned)\n",
    "\n",
    "print(total_vocab_count_cl, total_dis_count_cl, total_non_count_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7951680672268907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83      1091\n",
      "           1       0.83      0.66      0.73       813\n",
      "\n",
      "    accuracy                           0.80      1904\n",
      "   macro avg       0.80      0.78      0.78      1904\n",
      "weighted avg       0.80      0.80      0.79      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with cleaned data\n",
    "\n",
    "model3 = Pipeline([('vect', TfidfVectorizer()),\n",
    "               #('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model3.fit(X_train_cleaned, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred3 = model3.predict(X_test_cleaned)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred3, y_test))\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7946428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1091\n",
      "           1       0.77      0.73      0.75       813\n",
      "\n",
      "    accuracy                           0.79      1904\n",
      "   macro avg       0.79      0.79      0.79      1904\n",
      "weighted avg       0.79      0.79      0.79      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3_2 = Pipeline([('vect', CountVectorizer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model3_2.fit(X_train_cleaned, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred3_2 = model3_2.predict(X_test_cleaned)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred3_2, y_test))\n",
    "print(classification_report(y_test, y_pred3_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data performed worse... why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------- End of up-to-date material------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-9621dea74106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               ])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit_transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "model4 = Pipeline([('vect', MultiLabelBinarizer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred4, y_test))\n",
    "print(classification_report(y_test, y_pred4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating custom tokens\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def stem_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "stemmed_stopwords = [stemmer.stem(word) for word in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6055672268907563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74      1091\n",
      "           1       0.76      0.11      0.20       813\n",
      "\n",
      "    accuracy                           0.61      1904\n",
      "   macro avg       0.68      0.54      0.47      1904\n",
      "weighted avg       0.66      0.61      0.51      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4 = Pipeline([('vect', TfidfVectorizer(max_features=10,\n",
    "                         stop_words=stemmed_stopwords,\n",
    "                         tokenizer=stem_and_tokenize)),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred4= model4.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred4, y_test))\n",
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nicolemichaud/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Stemming didn't help, what about lemmatization?\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def lem_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "\n",
    "lemm_stopwords = [lemmatizer.lemmatize(word) for word in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5940126050420168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74      1091\n",
      "           1       0.78      0.07      0.13       813\n",
      "\n",
      "    accuracy                           0.59      1904\n",
      "   macro avg       0.68      0.53      0.43      1904\n",
      "weighted avg       0.67      0.59      0.48      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model5 = Pipeline([('vect', TfidfVectorizer(max_features=10,\n",
    "                         stop_words=lemm_stopwords,\n",
    "                         tokenizer=lem_and_tokenize)),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred5= model5.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred5, y_test))\n",
    "print(classification_report(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even worse than stemming...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This MultinomialNB estimator requires y to be passed, but the target y is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-38681ec39147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#count_vectorizer = feature_extraction.text.CountVectorizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 return last_step.fit(Xt, y,\n\u001b[0m\u001b[1;32m    379\u001b[0m                                      **fit_params_last_step).transform(Xt)\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requires_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    417\u001b[0m                     \u001b[0;34mf\"This {self.__class__.__name__} estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This MultinomialNB estimator requires y to be passed, but the target y is None."
     ]
    }
   ],
   "source": [
    "#count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vectors = model2.fit_transform(train_df[\"text\"])\n",
    "test_vectors = model2.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf4 = TfidfVectorizer(max_features=100)\n",
    "\n",
    "# Fit the vectorizer on X_train[\"text\"] and transform it\n",
    "X_train_vectorized4 = tfidf4.fit_transform(X_train[\"text\"])\n",
    "\n",
    "# Visually inspect the vectorized data\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized4, columns=tfidf4.get_feature_names())\n",
    "# note that this doesnt have stopwords removed!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr_features_cv = cross_val_score(clf, X_train_vectorized4, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "incr_features_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model3 = LogisticRegression()\n",
    "model3_cv = cross_val_score(model3, X_train_vectorized, y_train, scoring=\"f1\")\n",
    "model3_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building baseline model, try things to improve score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-ddaec5e7cabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                    \"be removed in 0.24.\")\n\u001b[1;32m   1879\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "sample_submission[\"target\"] = model2.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_vectorized = tfidf.fit_transform(train_df)\n",
    "test_df_vectorized = tfidf.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-83d004593746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               ])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \"\"\"\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "#best model:\n",
    "final = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "final.fit(train_df_vectorized, y)\n",
    "\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#y_pred = final.predict(test_df)\n",
    "\n",
    "#print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "#clf.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(evaluate using f1 metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
