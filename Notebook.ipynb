{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 4 Project - Kaggle Competition \"Natural Language Processing with Disaster Tweets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been accumulated from a number of tweets, some of which are about disasters, some of which are not. By creating a model for Natural Language Processing (NLP), we can predict whether or not a given tweet is about a real disaster or not. This can benefit companies who wish to monitor twitter in the event of an emergency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#nltk.download('punkt', quiet=True)\n",
    "np.random.seed(42)\n",
    "import seaborn as sns\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what is NOT a disaster tweet:\n",
    "train_df[train_df[\"target\"] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what IS a disaster tweet:\n",
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore other features\n",
    "# word frequencies for keyword column in 1 vs 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "armageddon               42\n",
       "deluge                   42\n",
       "harm                     41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"keyword\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing the top 10 keywords in both train_df and test_df to see if we notice any trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fatalities</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deluge</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>armageddon</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body%20bags</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sinking</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>damage</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>harm</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>collided</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>evacuate</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fear</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  keyword\n",
       "0   fatalities       45\n",
       "1       deluge       42\n",
       "2   armageddon       42\n",
       "3  body%20bags       41\n",
       "4      sinking       41\n",
       "5       damage       41\n",
       "6         harm       41\n",
       "7     collided       40\n",
       "8     evacuate       40\n",
       "9         fear       40"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_train_keywords = train_df['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_train_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_train_keywords['index'], x=top_train_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deluged</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rubble</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demolished</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annihilation</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first%20responders</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seismic</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>snowstorm</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obliteration</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sirens</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>avalanche</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  keyword\n",
       "0             deluged       23\n",
       "1              rubble       22\n",
       "2          demolished       22\n",
       "3        annihilation       21\n",
       "4  first%20responders       21\n",
       "5             seismic       21\n",
       "6           snowstorm       21\n",
       "7        obliteration       21\n",
       "8              sirens       21\n",
       "9           avalanche       20"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_test_keywords = test_df['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_test_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_test_keywords['index'], x=top_test_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing the top 10 keywords for the train_df for each target value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweets = train_df[train_df['target']==1]\n",
    "\n",
    "other_tweets = train_df[train_df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>10834</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cramer: Iger's 3 words that wrecked Disney's s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>10837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These boxes are ready to explode! Exploding Ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>10841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sirens everywhere!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>10848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I just heard a really loud bang and everyone i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4342 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword location  \\\n",
       "15       23      NaN      NaN   \n",
       "16       24      NaN      NaN   \n",
       "17       25      NaN      NaN   \n",
       "18       26      NaN      NaN   \n",
       "19       28      NaN      NaN   \n",
       "...     ...      ...      ...   \n",
       "7581  10833  wrecked  Lincoln   \n",
       "7582  10834  wrecked      NaN   \n",
       "7584  10837      NaN      NaN   \n",
       "7587  10841      NaN      NaN   \n",
       "7593  10848      NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "15                                       What's up man?       0  \n",
       "16                                        I love fruits       0  \n",
       "17                                     Summer is lovely       0  \n",
       "18                                    My car is so fast       0  \n",
       "19                         What a goooooooaaaaaal!!!!!!       0  \n",
       "...                                                 ...     ...  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "7582  Cramer: Iger's 3 words that wrecked Disney's s...       0  \n",
       "7584  These boxes are ready to explode! Exploding Ki...       0  \n",
       "7587                                 Sirens everywhere!       0  \n",
       "7593  I just heard a really loud bang and everyone i...       0  \n",
       "\n",
       "[4342 rows x 5 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>derailment</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wreckage</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outbreak</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debris</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil%20spill</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>typhoon</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>suicide%20bombing</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>evacuated</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rescuers</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index  keyword\n",
       "0         derailment       39\n",
       "1           wreckage       39\n",
       "2           outbreak       39\n",
       "3             debris       37\n",
       "4        oil%20spill       37\n",
       "5            typhoon       37\n",
       "6  suicide%20bombing       32\n",
       "7          evacuated       32\n",
       "8     suicide%20bomb       32\n",
       "9           rescuers       32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_dis_keywords = disaster_tweets['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_dis_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_dis_keywords['index'], x=top_dis_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body%20bags</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harm</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>armageddon</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deluge</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ruin</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>siren</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twister</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>explode</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fear</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  keyword\n",
       "0  body%20bags       40\n",
       "1         harm       37\n",
       "2   armageddon       37\n",
       "3      wrecked       36\n",
       "4       deluge       36\n",
       "5         ruin       36\n",
       "6        siren       35\n",
       "7      twister       35\n",
       "8      explode       35\n",
       "9         fear       35"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_other_keywords = other_tweets['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_other_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y=top_other_keywords['index'], x=top_other_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({nan: 61, 'fatalities': 45, 'armageddon': 42, 'deluge': 42, 'body%20bags': 41, 'damage': 41, 'harm': 41, 'sinking': 41, 'collided': 40, 'evacuate': 40, ...})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "train_freq_dist = FreqDist(train_df[\"keyword\"].explode())\n",
    "train_freq_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualizing what proportion of the training data are disaster tweets and non-disaster tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['target'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disaster_freqs = FreqDist(disaster_tweets[\"keyword\"].explode())\n",
    "#others_freqs = FreqDist(other_tweets[\"keyword\"].explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disaster_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size = df[['keyword','Store']].groupby(['Store'], as_index=False).sum()\n",
    "#Size.sort_values(by=['Size'],ascending=False).head(10)\n",
    "#train_freq_dist.plot(10)\n",
    "# Plot the top 10 tokens\n",
    "#visualize_top_10(train_freq_dist, \"Top 10 Word Frequency for 5 Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disaster_freqs.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#others_freqs.plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculating the probabilities of disaster and non-disaster tweets in the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4296597924602653\n",
      "0.5703402075397347\n"
     ]
    }
   ],
   "source": [
    "P_disasters = len(disaster_tweets) /(len(disaster_tweets)+len(other_tweets))\n",
    "P_non = len(other_tweets) /(len(other_tweets)+len(disaster_tweets))\n",
    "print(P_disasters)\n",
    "print(P_non)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace smoothing!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need set of unique tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = (tuple(nltk.bigrams(X_train,pad_left=True, pad_right=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigr = nltk.bigrams(X_train,pad_left=True, pad_right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalFreqDist with 5650 conditions>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencyDist = nltk.ConditionalFreqDist(bigr)\n",
    "frequencyDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laplace smoothing = used to correct probabilities of words so there are no zeroes\n",
    "#categories will be 1 and 0\n",
    "def vocab_maker(category):\n",
    "    vocab_category = set()\n",
    "    \n",
    "    for tweet in category:\n",
    "        words = tweet.split()\n",
    "        for word in words:\n",
    "            vocab_category.add(word)\n",
    "    return vocab_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dis = vocab_maker(disasters['text'])\n",
    "voc_non = vocab_maker(non_disasters['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5pm',\n",
       " 'prime',\n",
       " 'warfare',\n",
       " 'storm..like',\n",
       " 'cleav...',\n",
       " 'Fastpitch',\n",
       " 'TANK',\n",
       " 'Lose',\n",
       " \"we'll\",\n",
       " '@instapundit',\n",
       " 'pivot',\n",
       " 'http://t.co/Z2vDGIyOwf',\n",
       " 'Kicks',\n",
       " 'informant\\x89Ûªs',\n",
       " '@TeaFrystlik',\n",
       " '@BenAffleck',\n",
       " 'terrorism',\n",
       " \"'HUGE'\",\n",
       " \"i'd\",\n",
       " 'Elbow',\n",
       " 'CHILDREN',\n",
       " '@RT_America',\n",
       " 'it?',\n",
       " \"'Hopefully\",\n",
       " 'Metal)',\n",
       " 'comedy:',\n",
       " 'Ashes',\n",
       " 'http://t.co/a6Ro9bmXcy',\n",
       " 'http://t.co/TJyyFT6NV0',\n",
       " 'Marlon',\n",
       " 'http://t.co/0FS9kSV5xK',\n",
       " 'Vuitton',\n",
       " 'billion',\n",
       " 'http://t.co/yDJpOpH1DW',\n",
       " 'jinx',\n",
       " 'Carnegie',\n",
       " 'boy',\n",
       " 'lookss',\n",
       " 'Islamist',\n",
       " 'Tell',\n",
       " 'cocky',\n",
       " 'E',\n",
       " 'After-Hours',\n",
       " '-9]',\n",
       " '@Pam_Palmater',\n",
       " 'You...',\n",
       " 'http://t.co/BUMzvmwAM3',\n",
       " 'Muslims/terrorism?',\n",
       " 'mystery',\n",
       " 'based',\n",
       " '@tonyakappes11',\n",
       " 'intoxicated',\n",
       " 'Treblinka',\n",
       " '@Zak_Bagans',\n",
       " 'http://t.co/OMfGv9ma1W',\n",
       " 'Heading',\n",
       " \"'WOUNDED\",\n",
       " 'http://t.co/b1bx0ERuep',\n",
       " 'Mallord',\n",
       " 'http://t.co/u9LvvLzhYe)',\n",
       " 'http://t.co/wq3wJsgPHL',\n",
       " 'http://t.co/Mv7GgGlmVc',\n",
       " 'http://t.co/y5Yhbb0hkf',\n",
       " '@FinancialReview',\n",
       " '@DyannBridges',\n",
       " \"PRESENT)'\",\n",
       " 'http://t.co/7b2Wf6ovFK',\n",
       " 'ANYONE',\n",
       " 'Regent',\n",
       " 'Geometric',\n",
       " 'INTO',\n",
       " '8550013',\n",
       " 'protoshoggoth',\n",
       " 'responsibility',\n",
       " 'Printable',\n",
       " 'http://t.co/8bqjtp6iD5',\n",
       " 'is.',\n",
       " 'coyotes',\n",
       " 'america',\n",
       " '&amp;#163;163;millions.',\n",
       " 'http://t.co/R7pVTSdUmA',\n",
       " 'Ridah',\n",
       " 'girls!',\n",
       " 'Appreciate',\n",
       " 'shout',\n",
       " 'often',\n",
       " 'AUC',\n",
       " 'Closed',\n",
       " 'morning??',\n",
       " '@Wars_Goddess',\n",
       " 'tend',\n",
       " 'transgendered',\n",
       " 'http://t.co/jhpdSSVhvE',\n",
       " 'Markets',\n",
       " 'di...',\n",
       " 'http://t.co/WgasoeNCwc',\n",
       " 'Port',\n",
       " 'Reebok',\n",
       " 'http://t.co/o3wVScLiCX',\n",
       " 'starter',\n",
       " 'http://t.co/FPjLwOXKlg',\n",
       " 'Alarming',\n",
       " 'tops',\n",
       " 'horrors',\n",
       " 'http://t.co/0oms8rI3l1',\n",
       " 'WarriorCord',\n",
       " 'billings',\n",
       " 'released',\n",
       " 'us?Bush',\n",
       " 'TRAFFIC',\n",
       " 'Spears',\n",
       " 'things.',\n",
       " '300000',\n",
       " 'T-Shirt',\n",
       " 'http://t.co/ud7XObYUa1',\n",
       " 'gon',\n",
       " 'Tbh',\n",
       " 'mounting',\n",
       " 'LUNGS',\n",
       " 'plunging',\n",
       " 'Type',\n",
       " 'http://t.co/QQC0gKbEGs',\n",
       " 'climate',\n",
       " 'GOODE',\n",
       " 'Edit)',\n",
       " 'Apollo',\n",
       " 'bomber',\n",
       " 'Fun',\n",
       " 'http://t.co/RqIPGQslT6',\n",
       " 'http://t.co/AlUMrGl40e',\n",
       " '#leadership',\n",
       " '(#CUFI):',\n",
       " 'pregnant',\n",
       " '(ft.',\n",
       " 'Sun',\n",
       " 'nw',\n",
       " 'reasons',\n",
       " 'GTA',\n",
       " 'Leftwich',\n",
       " 'Worried',\n",
       " 'http://t.co/eG1fsKqBv6',\n",
       " 'Godly',\n",
       " 'Joe',\n",
       " 'Ars',\n",
       " 'greeting',\n",
       " 'exactly.',\n",
       " 'gypsy',\n",
       " 'Canvas',\n",
       " 'Fabric',\n",
       " 'Anger',\n",
       " 'brother-n-law',\n",
       " 'G+:',\n",
       " 'No',\n",
       " 'http://t.co/ajTXUafOEM',\n",
       " 'pledged',\n",
       " \"http://t.co/0jmKdTcYmJ'\",\n",
       " 'wrong.',\n",
       " 'drunk',\n",
       " 'debate',\n",
       " 'Shaolin',\n",
       " 'Bruv',\n",
       " '#Megaquake',\n",
       " 'http://t.co/0x8jAQToWM',\n",
       " 'terrorism.',\n",
       " 'FLATLINERS',\n",
       " 'targe...',\n",
       " 'yield',\n",
       " 'KAMON',\n",
       " 'Tragedy',\n",
       " 'Pits.',\n",
       " 'patch',\n",
       " '(one',\n",
       " '5.3',\n",
       " '@ANNIHILATION',\n",
       " 'locked',\n",
       " '#Age',\n",
       " '#ARMAGEDDON',\n",
       " 'Bad',\n",
       " 'niiiice',\n",
       " '2....',\n",
       " 'mercy.',\n",
       " 'dredougie:',\n",
       " 'run...',\n",
       " '@DJJOHNBLazE',\n",
       " 'zzzz',\n",
       " '@aida_de',\n",
       " \"'nope'??\",\n",
       " 'Kills',\n",
       " 'sanctions',\n",
       " '43',\n",
       " '#Paranormal',\n",
       " 'http://t.co/sKVNmtZGeG',\n",
       " 'EMP',\n",
       " '@HoneyBunzGem',\n",
       " 'http://t.co/qqSKYbARNg',\n",
       " '#jamaicaplain',\n",
       " '#WOD',\n",
       " 'like',\n",
       " 'Responders-',\n",
       " 'rivers',\n",
       " 'wayward',\n",
       " '@HalloIkBenWill',\n",
       " 'https://t.co/MmZgpHNKNP',\n",
       " 'van',\n",
       " 'nights',\n",
       " 'http://t.co/gGTmDqUdDo',\n",
       " 'Routing',\n",
       " 'TRUCK',\n",
       " 'ally',\n",
       " 'http://t.co/I2AAG6Lp6W',\n",
       " 'http://t.co/UooZXauS26',\n",
       " \"wouldn't\",\n",
       " 'http://t.co/wDUEaj8Q4J',\n",
       " 'Elem',\n",
       " 'Qty',\n",
       " 'activist',\n",
       " 'Twitter.',\n",
       " 'Groom',\n",
       " 'Snuff',\n",
       " 'saturated',\n",
       " 'Deco',\n",
       " 'Scourgue',\n",
       " 'http://t.co/SWwyLRk0fv',\n",
       " 'mid-morning',\n",
       " 'http://t.co/3i3d2NGeNt',\n",
       " 'era',\n",
       " 'http://t.co/U2dO2mC2ri',\n",
       " '250000',\n",
       " 'ROADWAY-PROPERTY',\n",
       " '#????',\n",
       " 'Proposed',\n",
       " '#gif',\n",
       " 'http://t.co/NKOu7zWwRT',\n",
       " 'Americans!',\n",
       " 'AM.',\n",
       " 'Bolshevik',\n",
       " 'XII:',\n",
       " 'olive',\n",
       " '@kasiakosek',\n",
       " 'http://t.co/9i6CrCRq2m',\n",
       " 'swollen',\n",
       " '@slone',\n",
       " 'Peace\\x89Ûª',\n",
       " 'Formed',\n",
       " '@NafeezAhmed',\n",
       " 'Mode',\n",
       " 'God',\n",
       " 'Explodes',\n",
       " 'Bard',\n",
       " 'HAMPSHIRE',\n",
       " 'Cell',\n",
       " 'narrator',\n",
       " \"America's\",\n",
       " 'http://t.co/CJHH17duli',\n",
       " \"Infomercial'\",\n",
       " '#randomthought',\n",
       " 'Plane',\n",
       " 'Arrested',\n",
       " 'toddler',\n",
       " 'http://t.co/aDSvDpNP3r',\n",
       " '#Bridgetown',\n",
       " 'Georgia',\n",
       " 'rants',\n",
       " 'http://t.co/kxpLYoM9RR',\n",
       " 'person?',\n",
       " 'Salem',\n",
       " '20:30:',\n",
       " 'http://t.co/79Fw9zWxtP',\n",
       " 'http://t.co/J2erZbMjQD',\n",
       " 'assistant',\n",
       " 'Mounts',\n",
       " '@medic914',\n",
       " 'HITS:',\n",
       " 'adorable.',\n",
       " 'July',\n",
       " 'http://t.co/OYY9MGW7HN',\n",
       " 'the',\n",
       " 'saat',\n",
       " 'bagging',\n",
       " 'tweets',\n",
       " 'Gunshot',\n",
       " 'MCHENRY',\n",
       " 'http://t.co/gHk9Xup6E0',\n",
       " 'Failure',\n",
       " 'fcked.',\n",
       " 'States',\n",
       " 'please!',\n",
       " 'psp',\n",
       " 'Step',\n",
       " 'war?',\n",
       " '@MithiTennis',\n",
       " 'ALL!',\n",
       " \"'shelter\",\n",
       " 'Ga.',\n",
       " '#Blowltan',\n",
       " \"Rescuers.....'The\",\n",
       " 'http://t.co/czpDn9oBiT',\n",
       " 'graduated',\n",
       " 'http://t.co/KkjP9KsBst',\n",
       " '#blessed',\n",
       " 'STARTS',\n",
       " '@violentfeminazi',\n",
       " 'windy',\n",
       " 'Carl',\n",
       " 'http://t.co/s0ctCQJvjX',\n",
       " 'Lives',\n",
       " 'Angelina',\n",
       " '#Horrible',\n",
       " 'valley',\n",
       " 'chemicals',\n",
       " '@95roots',\n",
       " 'S\\x89Û_',\n",
       " '#desolationofsmaug',\n",
       " 'h...',\n",
       " 'beneath',\n",
       " 'bite',\n",
       " 'http://t.co/bGeRLjamTE',\n",
       " 'Taiwan;',\n",
       " 'Lab',\n",
       " 'w/out',\n",
       " 'http://t.co/zqrcptLrUM',\n",
       " 'sign',\n",
       " 'outrage?',\n",
       " 'http://t.co/90L2lB5WMr',\n",
       " 'coercion',\n",
       " 'FINALLY',\n",
       " 'attacks.',\n",
       " 'http://t.co/m0utLDif77',\n",
       " 'http://t.co/jMBVPanXR3',\n",
       " 'Routine',\n",
       " 'http://t.co/RVczMimfVx',\n",
       " 'http://t.co/odmP01eyZU',\n",
       " 'bioter\\x89Û_',\n",
       " 'http://t.co/7enNulLKzM',\n",
       " 'Transporta...',\n",
       " 'http://t.co/ocojPPnRh1',\n",
       " 'Soo',\n",
       " \"Dorett's\",\n",
       " 'goin',\n",
       " 'Transcend:Blazing',\n",
       " 'purified.',\n",
       " 'Taking',\n",
       " 'Wreck.',\n",
       " 'Ticket',\n",
       " \"drill!'\",\n",
       " '#SaltRiverWildHorses',\n",
       " 'cries',\n",
       " 'Chuck',\n",
       " 'http://t.co/yi3OiVK2X4',\n",
       " 'Hundred',\n",
       " 'ensure',\n",
       " 'http://t.co/zLco4UE5OQ',\n",
       " 'isis',\n",
       " '#OOCVG',\n",
       " 'house',\n",
       " 'forming',\n",
       " 'Tenno.',\n",
       " 'flames....',\n",
       " 'Struggles',\n",
       " '(Arceen',\n",
       " 'condolence',\n",
       " 'y',\n",
       " 'CEST:',\n",
       " 'sifting',\n",
       " '@PianoHands',\n",
       " 'Val',\n",
       " 'THREAT',\n",
       " '@RealJaxClone',\n",
       " 'fresh',\n",
       " 'Manchester.',\n",
       " 'http://t.co/SQsyUeh4yI',\n",
       " 'choking',\n",
       " '#CS',\n",
       " 'Cipinang)',\n",
       " 'BOMBER',\n",
       " 'Lost',\n",
       " '#france',\n",
       " 'http://t.co/ciwwUQthin',\n",
       " 'sink.',\n",
       " 'illegally',\n",
       " 'Kindersley',\n",
       " '@MariaSherwood2',\n",
       " 'http://t.co/O7yYjLuKfJ',\n",
       " 'Quadrillion',\n",
       " 'bridge.',\n",
       " 'http://t.co/DtFSWNJZIL',\n",
       " \"he'd\",\n",
       " 'contig',\n",
       " 'Ill',\n",
       " '#nowplaying',\n",
       " 'Extender',\n",
       " 'W.M.',\n",
       " 'Talent:',\n",
       " 'Earnings',\n",
       " 'Arabic',\n",
       " 'copied...',\n",
       " '#SEBEE',\n",
       " 'aside',\n",
       " 'VTc',\n",
       " 'accept',\n",
       " '@SonofLiberty357',\n",
       " '4.',\n",
       " 'Call:',\n",
       " 'http://t.co/VmKexjTyG4',\n",
       " 'Pumpkins',\n",
       " 'clips',\n",
       " 'necessary',\n",
       " 'Brock',\n",
       " 'nawh',\n",
       " 'http://t.co/eaSlGeA1B7',\n",
       " 'misfit',\n",
       " '#OtleyHour',\n",
       " 'misled.',\n",
       " 'western',\n",
       " 'http://t.co/m9pXTo2kwW',\n",
       " 'HEY',\n",
       " 'Stop',\n",
       " 'Croydonization',\n",
       " 'Lord.',\n",
       " '@stvmlly',\n",
       " \"It'll\",\n",
       " '#anthrax',\n",
       " '$$$$',\n",
       " 'pet',\n",
       " 'emergency?',\n",
       " 'Collar',\n",
       " 'http://t.co/xQpn2zYkCt',\n",
       " 'http://t.co/ClOLmorpLd',\n",
       " 'Stole',\n",
       " 'obedience',\n",
       " 'Center;',\n",
       " \"'better\",\n",
       " 'http://t.co/0MNPCER9nO',\n",
       " 'actively',\n",
       " 'Response',\n",
       " '#Auction',\n",
       " 'AWFUL',\n",
       " 'areas.',\n",
       " '#hazmat',\n",
       " 'aimlessly',\n",
       " 'http://t.co/k6UEtsnLHT',\n",
       " 'rickets.',\n",
       " 'intelligence',\n",
       " 'Miami?',\n",
       " 'Legion',\n",
       " 'CARE',\n",
       " 'Battle',\n",
       " 'http://t.co/awtScUCBBV',\n",
       " 'catch!',\n",
       " 'wrong?',\n",
       " 'Bro',\n",
       " 'outbreaks',\n",
       " 'po',\n",
       " 'Mingo',\n",
       " 'ripped',\n",
       " 'movie.',\n",
       " 'buildup',\n",
       " 'More',\n",
       " 'origins',\n",
       " 'fifth',\n",
       " 'http://t.co/cT9ejXoLpu',\n",
       " 'gains',\n",
       " 'fide',\n",
       " '13000',\n",
       " 'content:',\n",
       " 'Holes',\n",
       " '#perspective',\n",
       " 'disappoints',\n",
       " 'leos',\n",
       " 'squabble',\n",
       " 'Megan',\n",
       " 'Geller',\n",
       " 'apartments.',\n",
       " 'fundwhen',\n",
       " 'RSX',\n",
       " 'JaN',\n",
       " 'Aug.',\n",
       " 'http://t.co/yoPeYPJkb2',\n",
       " 'Silas',\n",
       " 'Brasswork',\n",
       " 'Rescuers',\n",
       " 'distinct',\n",
       " 'bills',\n",
       " '$10M',\n",
       " 'Crushed',\n",
       " \"you'll\",\n",
       " 'setlist',\n",
       " 'State:',\n",
       " 'Orangi:',\n",
       " 'https://t.co/lUe3waeGpI',\n",
       " 'Sansa',\n",
       " 'fault',\n",
       " 'wknd',\n",
       " 'Sugar',\n",
       " 'flames',\n",
       " 'https://t.co/Gs0km0vlgk',\n",
       " 'memory.',\n",
       " 'tOSU',\n",
       " 'Are',\n",
       " 'http://t.co/PNaQXPrweg',\n",
       " \"collapsed'\",\n",
       " '@whedonesque',\n",
       " 'Optimization',\n",
       " 'responds.',\n",
       " 'PS1',\n",
       " 'Could',\n",
       " 'Naaa',\n",
       " 'http://t.co/tpW5gPmhQ4',\n",
       " 'Isla...',\n",
       " 'resort',\n",
       " \"talk='ecology'&amp;'human\",\n",
       " 'http://t.co/BP03eAFEWR',\n",
       " \"'Prince\",\n",
       " 'evil',\n",
       " 'help...',\n",
       " '@hoodedu',\n",
       " 'busting',\n",
       " 'when...',\n",
       " 'pull\\x89Û_one\\x89Û_you',\n",
       " 'stores.',\n",
       " '@firstpostin',\n",
       " 'says:',\n",
       " 'ATM',\n",
       " 'tightly*',\n",
       " '@wowsavannah',\n",
       " '#263Chat',\n",
       " 'moved',\n",
       " 'Forecast.',\n",
       " '#mix',\n",
       " '#Modi',\n",
       " '#Disaster.',\n",
       " \"'Er\",\n",
       " 'OKs',\n",
       " '@steph93065',\n",
       " 'dont',\n",
       " 'object.',\n",
       " 'Ali',\n",
       " 'HTML5',\n",
       " 'Target',\n",
       " 'magnificent',\n",
       " 'sewing',\n",
       " 'Bama',\n",
       " 'week!',\n",
       " 'WHITE',\n",
       " '#summerfate',\n",
       " 'Ten-4.',\n",
       " '@GunnersFan89',\n",
       " 'Fennovoima',\n",
       " 'at...',\n",
       " 'now;',\n",
       " 'penalties',\n",
       " 'rate.',\n",
       " 'specialists.',\n",
       " '17:26',\n",
       " 'effects',\n",
       " 'http://t.co/uiSNqIu3iF',\n",
       " 'landslide:',\n",
       " 'http://t.co/WR48AQTUm7',\n",
       " 'DEF',\n",
       " 'comes',\n",
       " 'NH',\n",
       " 'http://t.co/ciHC8Nrc9h',\n",
       " 'Underwriter',\n",
       " 'Collision',\n",
       " '@OU_WBBall',\n",
       " '#PeritoEnGrafoscopia',\n",
       " 'willinghearted',\n",
       " 'brush',\n",
       " 'answer.',\n",
       " '9',\n",
       " 'Golf',\n",
       " 'back!!',\n",
       " 'decayed;',\n",
       " 'life:',\n",
       " 'Monkeys',\n",
       " 'http://t.co/rb02svlpPu',\n",
       " 'http://t.co/TTb9oiL8R2',\n",
       " 'Nagasaki.',\n",
       " '#7',\n",
       " '1620',\n",
       " 'blubber!',\n",
       " 'Cher',\n",
       " 'trick',\n",
       " 'http://t.co/kEa5l3b1AE',\n",
       " 'http://t.co/CXI82rFiFS',\n",
       " 'SUCH',\n",
       " '#ProfitToThePeople',\n",
       " 'Hailstorm.',\n",
       " 'Information',\n",
       " 'progress',\n",
       " 'shaking!',\n",
       " '@WeAreTheNews',\n",
       " 'RIOTS',\n",
       " 'gf',\n",
       " 'Incredulous',\n",
       " '688',\n",
       " '@Louis_Tomlinson',\n",
       " '@_301DC',\n",
       " 'Lara',\n",
       " 'THEIR',\n",
       " 'dazzle',\n",
       " '100s',\n",
       " 'waters-land',\n",
       " 'http://t.co/80DzgCo6Vc',\n",
       " 'sensei',\n",
       " 'Freaks',\n",
       " 'Mod',\n",
       " 'survive!',\n",
       " 'plug',\n",
       " 'Barry',\n",
       " 'LancasterOnline',\n",
       " 'Dates',\n",
       " 'http://t.co/ZT5OFbiwtD',\n",
       " '@mishacollins',\n",
       " 'fans.',\n",
       " '@EmergencyMgtMag',\n",
       " '#PPSellsBabyParts',\n",
       " 'drinking',\n",
       " 'Homegrown',\n",
       " '#AyekoRadio',\n",
       " '2019',\n",
       " 'medic',\n",
       " 'desecrates',\n",
       " 'injured:',\n",
       " 'http://t.co/ipT0hoNoTI',\n",
       " 'Strange',\n",
       " \"#landslide'\",\n",
       " 'bloggers',\n",
       " 'nexus',\n",
       " 'see',\n",
       " 'critical',\n",
       " 'Shemesh;',\n",
       " '@thisisperidot',\n",
       " '@AdamTuss',\n",
       " 'thee.',\n",
       " 'Vegas/Solitude',\n",
       " 'Beaverton.',\n",
       " 'crocodile',\n",
       " 'scared',\n",
       " 'sneaks',\n",
       " 'insane',\n",
       " 'debate;',\n",
       " 'http://t.co/rGjJuMnNah',\n",
       " 'DOES',\n",
       " 'Kunstler:',\n",
       " ':p',\n",
       " 'suffering',\n",
       " '@DianneG:',\n",
       " 'BITCH',\n",
       " 'Maine',\n",
       " 'Satchel',\n",
       " '#Hwy401',\n",
       " 'starring...',\n",
       " 'plenty',\n",
       " '@SonyProUSA',\n",
       " '295SS-100',\n",
       " 'Hours',\n",
       " 'http://t.co/V1SFlLOWGh',\n",
       " 'Kelby',\n",
       " '#deadgrassandflowers',\n",
       " 'plastic',\n",
       " 'alien',\n",
       " 'desolate:',\n",
       " 'http://t.co/6jjvCDN4TI',\n",
       " 'Nuclear-Deal:',\n",
       " '1000s',\n",
       " '12.5%',\n",
       " 'http://t.co/xwVW1sft4I',\n",
       " '@PlayOverwatch',\n",
       " 'http://t.co/hHZY3oqeLa',\n",
       " 'backup.',\n",
       " '@sholt87',\n",
       " 'protestors.',\n",
       " 'jaiden',\n",
       " 'sentenced',\n",
       " 'st...',\n",
       " 'What',\n",
       " '[Photo]:',\n",
       " '@abandonedpics',\n",
       " 'http://t.co/N2bCf4M64V',\n",
       " 'drivers',\n",
       " 'News3LV',\n",
       " 'WY.',\n",
       " 'http://t.co/cM8UnI1mRG',\n",
       " \"'Without\",\n",
       " 'away..',\n",
       " 'fees.',\n",
       " 'Percent',\n",
       " '@__srajapakse__',\n",
       " '#WNIAGospel',\n",
       " 'Us?',\n",
       " 'carful',\n",
       " 'certificates',\n",
       " 'scenario?',\n",
       " 'Author',\n",
       " 'size',\n",
       " '#Floridians',\n",
       " 'Aftershock:',\n",
       " 'https://t.co/0rNY349UnT',\n",
       " 'jail',\n",
       " 'Venezuela',\n",
       " 'east',\n",
       " 'morning',\n",
       " 'water\\x89Û_',\n",
       " 'happing',\n",
       " 'interviews',\n",
       " 'galaxy',\n",
       " 'Saturn',\n",
       " 'LITTLE',\n",
       " \"Bing's\",\n",
       " '@BestComedyVine',\n",
       " 'destroyed',\n",
       " '#theneeds',\n",
       " 'song??',\n",
       " 'https://t.co/rosVXQeLQj',\n",
       " 'Kalle',\n",
       " \"'My\",\n",
       " 'donå«t',\n",
       " 'you.??',\n",
       " 'http://t.co/Hz4lKFfC59',\n",
       " 'Live',\n",
       " '@adrian_peel',\n",
       " 'Highsmith',\n",
       " 'http://t.co/x8zqbwNfO1',\n",
       " \"police'\",\n",
       " '#hiring!',\n",
       " '501',\n",
       " 'Media:',\n",
       " 'recipes',\n",
       " 'notes',\n",
       " 'options',\n",
       " 'http://t.co/qr6BtDCqCj',\n",
       " '(at',\n",
       " 'Brazilian',\n",
       " 'scattered',\n",
       " 'kabwandi_:',\n",
       " 'Tough',\n",
       " '@afterShock_DeLo',\n",
       " 'https://t.co/8u07FoqjzW',\n",
       " \"How's\",\n",
       " 'http://t.co/Es1b3lywAy',\n",
       " 'employs',\n",
       " 'http://t.co/MgR809yc5a',\n",
       " 'Backpack',\n",
       " 'wht',\n",
       " '@hlportal',\n",
       " 'Bethlehem',\n",
       " 'http://t.co/M78ir0IK01\\x89Û\\x9d',\n",
       " 'hi\\x89ÛÓtech',\n",
       " 'headlinelike',\n",
       " 'http://t.co/epABiNcZmJ',\n",
       " 'ensuring',\n",
       " 'Whitbourne',\n",
       " 'r...',\n",
       " 'day.http://t.co/8Vzl1ns2iO',\n",
       " 'us:',\n",
       " 'Cool',\n",
       " 'Rocket',\n",
       " 'Precious',\n",
       " 'http://t.co/5zDbTktwW7',\n",
       " 'Edwards',\n",
       " 'Cyclists',\n",
       " 'miniature',\n",
       " '@HopefulBatgirl',\n",
       " 'hunt',\n",
       " 'Emile',\n",
       " 'leadership',\n",
       " 'remind',\n",
       " 'insomniacs',\n",
       " 'Birthday',\n",
       " '@I_AmTalia',\n",
       " 'Hey',\n",
       " \"Street'\",\n",
       " 'icicle',\n",
       " '@AlexeiVolkov1',\n",
       " \"'@Ma3Route:\",\n",
       " '(cover',\n",
       " 'Notley',\n",
       " '#freespeech',\n",
       " 'Airplane',\n",
       " 'graveyard',\n",
       " 'http://t.co/YhH7X0MAio',\n",
       " 'all-time',\n",
       " 'redesigned.',\n",
       " 'Call',\n",
       " 'pll',\n",
       " 'Out:',\n",
       " 'Mega',\n",
       " 'shall',\n",
       " 'collide:',\n",
       " 'http://t.co/gtHddzAvhg',\n",
       " 'Thousands',\n",
       " 'http://t.co/frpbNhVPyI',\n",
       " '25',\n",
       " '@suelinflower',\n",
       " '#digitalhealth',\n",
       " 'Changes',\n",
       " 'http://t.co/iZJToojzKp',\n",
       " 'Xela',\n",
       " 'WI',\n",
       " 'HAPPINESS',\n",
       " 'incredible',\n",
       " 'Lucio!!',\n",
       " '@riverroaming',\n",
       " 'airhorns',\n",
       " 'migrant',\n",
       " 'hijack',\n",
       " 'since',\n",
       " '#LittleWomenLA',\n",
       " 'http://t.co/Ev3nX9scx3',\n",
       " '#BBSNews',\n",
       " 'one...',\n",
       " 'Weston',\n",
       " 'Dorrie',\n",
       " 'http://t.co/mFJxh4p51U',\n",
       " 'OUTSIDE',\n",
       " 'unveiled',\n",
       " 'Within',\n",
       " 'MLK',\n",
       " 'e',\n",
       " 'epileptic\\x89Û_',\n",
       " 'knocking',\n",
       " 'Firetruck',\n",
       " 'http://t.co/YSXhFWMGOD',\n",
       " 'Delhi',\n",
       " 'looses',\n",
       " 'Tonto',\n",
       " 'http://t.co/4xB4ZwyhCt',\n",
       " 'Saudi',\n",
       " '@CheetosArabia',\n",
       " '@cnnbrk',\n",
       " 'Rory',\n",
       " 'flew',\n",
       " '#askH3cz',\n",
       " 'wy',\n",
       " 'ALBUM',\n",
       " 'store',\n",
       " 'Broke',\n",
       " '#ROH3SmantiBatam',\n",
       " 'Fantasy**',\n",
       " 'http://t.co/Qmo1TxxDkj',\n",
       " 'http://t.co/9xoHmMlMDY',\n",
       " '(xl61-62)',\n",
       " 'Cessna',\n",
       " 'http://t.co/9DVU1RidZ3',\n",
       " 'Contemporary',\n",
       " 'improvement.',\n",
       " 'factual',\n",
       " 'hurt',\n",
       " '#Live',\n",
       " '----&gt;',\n",
       " 'searching',\n",
       " 'HERE',\n",
       " 'approves',\n",
       " 'biblical',\n",
       " 'http://t.co/ZPxE3fMYNG',\n",
       " '@Groupon_UK',\n",
       " 'Caption',\n",
       " 'Been',\n",
       " 'http://t.co/QWpUxPyWbF',\n",
       " 'http://t.co/ZL7ojdAj3u',\n",
       " 'mfs',\n",
       " \"CHONCe'\",\n",
       " '@Jennife29916207',\n",
       " \"'Use\",\n",
       " 'itz',\n",
       " '\\x89Û÷Institute',\n",
       " 'exercise',\n",
       " 'Elementary',\n",
       " 'telly',\n",
       " 'http://t.co/aeZ3aK1lRN',\n",
       " 'http://t.co/M8CIKs60BX',\n",
       " 'imam!',\n",
       " 'occurs?',\n",
       " 'wonder.',\n",
       " 'case?',\n",
       " 'fully',\n",
       " \"#don'tpanic\",\n",
       " 'mark)',\n",
       " 'BULL',\n",
       " '[Reuters]',\n",
       " 'calgary',\n",
       " 'http://t.co/kLtIt88AS3',\n",
       " 'Property-Casualty',\n",
       " '300W',\n",
       " 'akame',\n",
       " 'charged',\n",
       " 'Bolsters',\n",
       " 'Looks:',\n",
       " 'avoided',\n",
       " 'Fighting',\n",
       " 'camps',\n",
       " \"'it's\",\n",
       " 'supernatural',\n",
       " 'hand.',\n",
       " 'STILL',\n",
       " 'need...',\n",
       " 'evacuated!!',\n",
       " 'https://t.co/V6qxnFHRxF',\n",
       " '@LifeAintFairKid',\n",
       " 'http://t.co/NnylXhInPx',\n",
       " 'Co',\n",
       " 'http://t.co/C0nKGp6w03åÊ',\n",
       " 'http://t.co/iXiYBAp8Qa',\n",
       " 'Issued',\n",
       " 'wakho.',\n",
       " \"'Food\",\n",
       " '@Kirafrog',\n",
       " '@TfLBusAlerts',\n",
       " \"http://t.co/NGEHhG9YGa'\",\n",
       " 'why',\n",
       " 'Allows',\n",
       " 'http://t.co/roCyyEI2dM',\n",
       " '@ushiocomics',\n",
       " 'trampling',\n",
       " 'election.',\n",
       " 'Tweak',\n",
       " \"'bioterror-\",\n",
       " 'loud.',\n",
       " 'å_?',\n",
       " 'http://t.co/bzZdeDcthL',\n",
       " 'Foursquare.',\n",
       " 'http://t.co/VoYrUxcrIN',\n",
       " 'Idea',\n",
       " '*se',\n",
       " 'Bass',\n",
       " 'Indianperpetrated',\n",
       " 'http://t.co/qd3DSSFWUE',\n",
       " 'Bridgeport',\n",
       " 'pact',\n",
       " '#theBargain',\n",
       " '@oliviaapalmerr',\n",
       " 'DR',\n",
       " 'superiority',\n",
       " 'darsena',\n",
       " '(18+)',\n",
       " 'entirely',\n",
       " 'Survive',\n",
       " 'wew',\n",
       " 'knew',\n",
       " 'pressed',\n",
       " 'AN',\n",
       " 'http://t.co/ZggpaCjP7D',\n",
       " 'crews..',\n",
       " 'SE',\n",
       " 'VINE',\n",
       " 'Challenging',\n",
       " '@Snazzychipz',\n",
       " 'http://t.co/13W8CyukKZ',\n",
       " '@NDzedze',\n",
       " 'http://t.co/ykVsttvDWo',\n",
       " '#UK',\n",
       " '#gms',\n",
       " 'dealings',\n",
       " 'Assad',\n",
       " 'Downtown',\n",
       " 'http://t.co/fnmJE8GF7m',\n",
       " '#arts',\n",
       " 'Assessment',\n",
       " 'Join',\n",
       " 'income',\n",
       " 'prosecute',\n",
       " 'on:',\n",
       " 'campground',\n",
       " 'http://t.co/F8GvWkFqox',\n",
       " 'Hurricane',\n",
       " 'okay.',\n",
       " 'hotspot.',\n",
       " '#sustainable',\n",
       " '@slimebeast',\n",
       " 'campaign:',\n",
       " '[Question]',\n",
       " 'Alois',\n",
       " 'http://t.co/XBNLSBzzgI',\n",
       " 'Typhoon-Devastated',\n",
       " 'thank',\n",
       " 'http://t.co/dhGAVw8bSW',\n",
       " 'Human',\n",
       " '@BritishBakeOff',\n",
       " 'lith',\n",
       " 'https://t.co/cic7h64Qv8',\n",
       " 'http://t.co/c1H7JECFrV',\n",
       " 'http://t.co/RG4JIsHyBs',\n",
       " '@flowri',\n",
       " 'legit',\n",
       " 'http://t.co/CcvcTe3lCw',\n",
       " \"'you\",\n",
       " 'https://t.co/cyU8zxw1oH',\n",
       " 'Trunk',\n",
       " 'quarantine.',\n",
       " 'C&gt;',\n",
       " '@Stephen_Georg',\n",
       " 'film.',\n",
       " 'http://t.co/jBJRg3eP1Q',\n",
       " 'Angela',\n",
       " 'http://t.co/EQjCpWILVn:',\n",
       " 'landowner',\n",
       " 'leo',\n",
       " 'challenge',\n",
       " '#ClubBanger',\n",
       " ...}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_all = voc_dis.union(voc_non)\n",
    "voc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-44f8e4ecfb2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "from nltk import *\n",
    "\n",
    "train_df['text'].vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_count = len(voc_all)\n",
    "total_dis_count = len(voc_dis)\n",
    "total_non_count = len(voc_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31924 16150 20560\n"
     ]
    }
   ],
   "source": [
    "print(total_vocab_count, total_dis_count, total_non_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencyDist = nltk.ConditionalFreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalProbDist with 0 conditions>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilityDist = nltk.ConditionalProbDist(frequencyDist, nltk.LaplaceProbDist, bins=frequencyDist.N())\n",
    "probabilityDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculating whether either disaster or non-disaster tweets contain a significantly different proportion of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    7575\n",
       "True       38\n",
       "Name: contains_number, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_query = r'\\$(?:\\d)?'\n",
    "\n",
    "train_df[\"contains_number\"] = train_df[\"text\"].str.contains(num_query)\n",
    "train_df[\"contains_number\"].value_counts()\n",
    "#fig, axes = setup_five_subplots()\n",
    "#plot_distribution_of_column_by_category(\"contains_price\", axes, \"Freqency of Posts Containing Prices for\")\n",
    "#fig.suptitle(\"Distributions of Posts Containing Prices by Category\", fontsize=24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3241\n",
       "True       22\n",
       "Name: contains_number, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"contains_number\"] = test_df[\"text\"].str.contains(num_query)\n",
    "test_df[\"contains_number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of disaster tweets containing numbers: 0.5016501650165017\n",
      "percent of non-disaster tweets containing numbers: 0.6788028386300524\n"
     ]
    }
   ],
   "source": [
    "print(\"percent of disaster tweets containing numbers:\", ((38/7575)*100))\n",
    "print(\"percent of non-disaster tweets containing numbers:\", ((22/3241)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight difference, but overall this is probably not very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-96f886141f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n -' ]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-96f886141f9f>\u001b[0m in \u001b[0;36mclean_keywords\u001b[0;34m(keyword)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Clean keywords for better idea of trends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'%20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#Clean keywords for better idea of trends\n",
    "def clean_keywords(keyword):\n",
    "    cleaned = re.sub(r'%20', ' ', keyword)\n",
    "    return cleaned\n",
    "def remove_accents(keyword):\n",
    "    cleaned = unidecode.unidecode(keyword)\n",
    "    return cleaned\n",
    "def remove_punctuation(keyword):\n",
    "    cleaned = re.sub(r\"[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n -' ]\",\" \",keyword)\n",
    "    return cleaned\n",
    "#train_df['keyword'].apply(clean_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_other_keywords = other_tweets['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_other_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=top_dis_keywords['index'], x=top_dis_keywords['keyword']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_other_keywords = other_tweets['keyword'].value_counts()[:10].sort_values(ascending=False).reset_index()\n",
    "top_other_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = train_df.drop(columns=['target', 'contains_number'])\n",
    "#y_train = train_df[['target']]\n",
    "#X_test = test_df\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = train_df.text\n",
    "y = train_df.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    @dicehateme @PuppyShogun This makes sense. Pap...\n",
       "6351    '@CatoInstitute: The causes of federal failure...\n",
       "3443    Well as I was chaning an iPad screen it fuckin...\n",
       "7164    the war on drugs has turned the U.S. into a WA...\n",
       "7037    Obama Declares Disaster for Typhoon-Devastated...\n",
       "                              ...                        \n",
       "5226    @Eganator2000 There aren't many Obliteration s...\n",
       "5390    just had a panic attack bc I don't have enough...\n",
       "860     Omron HEM-712C Automatic Blood Pressure Monito...\n",
       "7603    Officials say a quarantine is in place at an A...\n",
       "7270    I moved to England five years ago today. What ...\n",
       "Name: text, Length: 5709, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'@CatoInstitute: The causes of federal failure are deeply structural and they will not be easily solved: http://t.co/H2XcaX4jbU'\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = X_train.iloc[1]\n",
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\",\n",
       " '@',\n",
       " 'CatoInstitute',\n",
       " ':',\n",
       " 'The',\n",
       " 'causes',\n",
       " 'of',\n",
       " 'federal',\n",
       " 'failure',\n",
       " 'are',\n",
       " 'deeply',\n",
       " 'structural',\n",
       " 'and',\n",
       " 'they',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'easily',\n",
       " 'solved',\n",
       " ':',\n",
       " 'http',\n",
       " ':',\n",
       " '//t.co/H2XcaX4jbU',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the cleaned tweets data:\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_sample_tweet = word_tokenize(train_sample)\n",
    "tokenized_sample_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the data:\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)\n",
    "\n",
    "X_train_tokenized = X_train.copy()\n",
    "X_test_tokenized = X_test.copy()\n",
    "X_train_tokenized = X_train.apply(tokenizer.tokenize)\n",
    "X_test_tokenized = X_test.apply(tokenizer.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    @dicehateme @PuppyShogun This makes sense. Pap...\n",
       "6351    '@CatoInstitute: The causes of federal failure...\n",
       "3443    Well as I was chaning an iPad screen it fuckin...\n",
       "7164    the war on drugs has turned the U.S. into a WA...\n",
       "7037    Obama Declares Disaster for Typhoon-Devastated...\n",
       "                              ...                        \n",
       "5226    @Eganator2000 There aren't many Obliteration s...\n",
       "5390    just had a panic attack bc I don't have enough...\n",
       "860     Omron HEM-712C Automatic Blood Pressure Monito...\n",
       "7603    Officials say a quarantine is in place at an A...\n",
       "7270    I moved to England five years ago today. What ...\n",
       "Name: text, Length: 5709, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Just\n",
       "0        happened\n",
       "0        terrible\n",
       "0             car\n",
       "0           crash\n",
       "          ...    \n",
       "3262          its\n",
       "3262    Municipal\n",
       "3262    Emergency\n",
       "3262         Plan\n",
       "3262     yycstorm\n",
       "Name: text_tokenized, Length: 50940, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "train_df[\"text_tokenized\"] = train_df[\"text\"].apply(tokenizer.tokenize)\n",
    "test_df[\"text_tokenized\"] = test_df[\"text\"].apply(tokenizer.tokenize)\n",
    "\n",
    "train_df[\"text_tokenized\"].explode()\n",
    "test_df[\"text_tokenized\"].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def visualize_top_10(freq_dist, title):\n",
    "\n",
    "    # Extract data for plotting\n",
    "    top_10 = list(zip(*freq_dist.most_common(10)))\n",
    "    tokens = top_10[0]\n",
    "    counts = top_10[1]\n",
    "\n",
    "    # Set up plot and plot data\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(tokens, counts)\n",
    "\n",
    "    # Customize plot appearance\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    \n",
    "#visualize_top_10(example_freq_dist, \"Top 10 Word Frequency for Example Tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_freq_dist = FreqDist(train_df[\"text_tokenized\"].explode())\n",
    "visualize_top_10(train_freq_dist, \"Top 10 Word Frequency for train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_freq_dist = FreqDist(test_df[\"text_tokenized\"].explode())\n",
    "visualize_top_10(test_freq_dist, \"Top 10 Word Frequency for test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contains_number</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contains_number   id  keyword  location  target  text  text_tokenized\n",
       "0              0.0  1.0      0.0       0.0     0.0   0.0             0.0\n",
       "1              0.0  0.0      1.0       0.0     0.0   0.0             0.0\n",
       "2              0.0  0.0      0.0       1.0     0.0   0.0             0.0\n",
       "3              0.0  0.0      0.0       0.0     0.0   1.0             0.0\n",
       "4              0.0  0.0      0.0       0.0     1.0   0.0             0.0\n",
       "5              1.0  0.0      0.0       0.0     0.0   0.0             0.0\n",
       "6              0.0  0.0      0.0       0.0     0.0   0.0             1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is this cell necessary?\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10)\n",
    "#max_features=None\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n",
    "X_test_vectorized = tfidf.transform(X_test)\n",
    "\n",
    "# Which do I use?? The whole train_df or just X_train?\n",
    "\n",
    "train_df_vectorized = tfidf.fit_transform(train_df)\n",
    "test_df_vectorized = tfidf.transform(test_df)\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(train_df_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    [dicehateme, PuppyShogun, This, makes, sense, ...\n",
       "6351    [CatoInstitute, The, causes, of, federal, fail...\n",
       "3443    [Well, as, was, chaning, an, iPad, screen, it,...\n",
       "7164    [the, war, on, drugs, has, turned, the, into, ...\n",
       "7037    [Obama, Declares, Disaster, for, Typhoon, Deva...\n",
       "                              ...                        \n",
       "5226    [Eganator2000, There, aren, many, Obliteration...\n",
       "5390    [just, had, panic, attack, bc, don, have, enou...\n",
       "860     [Omron, HEM, 712C, Automatic, Blood, Pressure,...\n",
       "7603    [Officials, say, quarantine, is, in, place, at...\n",
       "7270    [moved, to, England, five, years, ago, today, ...\n",
       "Name: text, Length: 5709, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Madhya',\n",
       " 'Pradesh',\n",
       " 'Train',\n",
       " 'Derailment',\n",
       " 'Village',\n",
       " 'Youth',\n",
       " 'Saved',\n",
       " 'Many',\n",
       " 'Lives']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized.iloc[70][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Word Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try count vectorization, then tf-idf ?\n",
    "# Creating a 'bag of words'\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer(max_features=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>co</th>\n",
       "      <th>for</th>\n",
       "      <th>http</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5709 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      and  co  for  http  in  is  of  the  to  you\n",
       "0       1   0    0     0   0   0   0    0   1    0\n",
       "1       1   1    0     1   0   0   1    1   0    0\n",
       "2       1   0    0     0   0   1   0    1   1    0\n",
       "3       0   0    0     0   0   0   0    2   0    0\n",
       "4       0   0    1     0   0   0   0    0   0    0\n",
       "...   ...  ..  ...   ...  ..  ..  ..  ...  ..  ...\n",
       "5704    0   0    0     0   0   0   0    0   1    0\n",
       "5705    1   0    1     0   0   0   0    1   1    0\n",
       "5706    1   2    0     2   0   0   0    0   0    0\n",
       "5707    0   1    0     1   1   1   0    0   0    0\n",
       "5708    0   1    0     1   0   0   1    0   1    0\n",
       "\n",
       "[5709 rows x 10 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count_vectorized = count_vec.fit_transform(X_train)\n",
    "X_test_count_vectorized = count_vec.transform(X_test)\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_count_vectorized, columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>.</th>\n",
       "      <th>:</th>\n",
       "      <th>?</th>\n",
       "      <th>@</th>\n",
       "      <th>a</th>\n",
       "      <th>http</th>\n",
       "      <th>in</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362669</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.746706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346645</td>\n",
       "      <td>0.403974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785442</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521150</td>\n",
       "      <td>0.607338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825513</td>\n",
       "      <td>0.291642</td>\n",
       "      <td>0.406374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480049</td>\n",
       "      <td>0.324776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.512819</td>\n",
       "      <td>0.362343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5709 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        #         .         :    ?         @         a      http        in  \\\n",
       "0     0.0  0.660024  0.000000  0.0  0.660956  0.000000  0.000000  0.000000   \n",
       "1     0.0  0.000000  0.792802  0.0  0.391163  0.000000  0.294835  0.000000   \n",
       "2     0.0  0.746706  0.000000  0.0  0.000000  0.398839  0.000000  0.000000   \n",
       "3     0.0  0.422978  0.000000  0.0  0.000000  0.451852  0.000000  0.000000   \n",
       "4     0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "...   ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "5704  0.0  0.000000  0.417074  0.0  0.617344  0.000000  0.000000  0.000000   \n",
       "5705  0.0  0.000000  0.000000  0.0  0.000000  0.599619  0.000000  0.000000   \n",
       "5706  0.0  0.000000  0.667451  0.0  0.000000  0.000000  0.744654  0.000000   \n",
       "5707  0.0  0.000000  0.261405  0.0  0.000000  0.825513  0.291642  0.406374   \n",
       "5708  0.0  0.480049  0.324776  0.0  0.000000  0.512819  0.362343  0.000000   \n",
       "\n",
       "           the        to  \n",
       "0     0.000000  0.357079  \n",
       "1     0.362669  0.000000  \n",
       "2     0.346645  0.403974  \n",
       "3     0.785442  0.000000  \n",
       "4     0.000000  0.000000  \n",
       "...        ...       ...  \n",
       "5704  0.000000  0.667035  \n",
       "5705  0.521150  0.607338  \n",
       "5706  0.000000  0.000000  \n",
       "5707  0.000000  0.000000  \n",
       "5708  0.000000  0.519421  \n",
       "\n",
       "[5709 rows x 10 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10, tokenizer=word_tokenize)\n",
    "\n",
    "\n",
    "X_train_vectorized1 = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Visually inspect the vectorized data\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized1, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Building a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8035714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84      1091\n",
      "           1       0.81      0.70      0.75       813\n",
      "\n",
      "    accuracy                           0.80      1904\n",
      "   macro avg       0.81      0.79      0.80      1904\n",
      "weighted avg       0.80      0.80      0.80      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "baseline_model = Pipeline([('vect', CountVectorizer(tokenizer=word_tokenize)),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_features\": [None ,10, 100, 200],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator TfidfVectorizer(max_features=10,\n                tokenizer=<function word_tokenize at 0x7fc9844139d0>) does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-fea795e52f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0m\u001b[1;32m    655\u001b[0m             self.estimator, scoring=self.scoring)\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    474\u001b[0m                                                           str):\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator TfidfVectorizer(max_features=10,\n                tokenizer=<function word_tokenize at 0x7fc9844139d0>) does not."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(tfidf , params, cv=3, return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train, score='f1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Laplace' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-f4ab8520a0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Laplace' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# model with TF-IDF Vectorizer instead of CountVectorizer, added tfidfTransformer\n",
    "model2 = Pipeline([('vect', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "                   #('tfidf', TfidfTransformer()),\n",
    "                   ('clf', MultinomialNB())\n",
    "                   #('tokenizer', RegexpTokenizer(basic_token_pattern))\n",
    "                  ])\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "from nltk.lm import Laplace\n",
    "model2 = Laplace(1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred2, y_test))\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch??\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB() )\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'alpha': (1, 2, 3),\n",
    "    'class_prior': (),\n",
    "    'fit_prior': ()\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'reg__alpha': (0.00001, 0.000001),\n",
    "    #\"max_features\": [None ,10, 100, 200],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'class_prior', 'fit_prior'])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter max_features for estimator Pipeline(steps=[('vect', TfidfVectorizer()), ('tfidf', TfidfTransformer()),\n                ('clf', MultinomialNB())]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-231b374c92ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[1;32m    250\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter max_features for estimator Pipeline(steps=[('vect', TfidfVectorizer()), ('tfidf', TfidfTransformer()),\n                ('clf', MultinomialNB())]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5151    dicehateme puppyshogun makes sense paper beats...\n",
       "6351    ' catoinstitute causes federal failure deeply ...\n",
       "3443    well chaning ipad screen fucking exploded glas...\n",
       "7164                          war drugs turned u war zone\n",
       "7037    obama declares disaster typhoon devastated saipan\n",
       "5159    according prophecy also cnn mac tablet complet...\n",
       "1010           body bagged rt lac drake body bagging meek\n",
       "5070        connorfranta askconnor natural disaster would\n",
       "2069    soapscoop need confirm ross dead cause dont tr...\n",
       "931     libraryeliza get taylorswift 'bump' approval p...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords, punctuation, numbers, and bad characters \n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "no_bad_chars = re.compile('[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n - ]')\n",
    "no_nums = re.compile('[\\d-]')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = no_bad_chars.sub(' ', text) \n",
    "    text = no_nums.sub('', text) \n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords_list)\n",
    "    return text\n",
    "    \n",
    "X_train_cleaned = X_train.apply(clean_text)\n",
    "X_test_cleaned = X_test.apply(clean_text)\n",
    "X_train_cleaned.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-2fe191bcb84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdisasters_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnon_disasters_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "# see vocab for cleaned data\n",
    "train_df_cleaned = train_df['text'].apply(clean_text)\n",
    "\n",
    "disasters_cleaned = train_df_cleaned[train_df_cleaned['target']==1]\n",
    "non_disasters_cleaned = train_df_cleaned[train_df_cleaned['target']==0]\n",
    "\n",
    "voc_dis_cleaned = vocab_maker(disasters_cleaned['text'])\n",
    "voc_non_cleaned = vocab_maker(non_disasters_cleaned['text'])\n",
    "\n",
    "voc_all_cleaned = voc_dis_cleaned.union(voc_non_cleaned)\n",
    "voc_all_cleaned\n",
    "\n",
    "total_vocab_count_cl = len(voc_all_cleaned)\n",
    "total_dis_count_cl = len(voc_dis_cleaned)\n",
    "total_non_count_cl = len(voc_non_cleaned)\n",
    "\n",
    "print(total_vocab_count_cl, total_dis_count_cl, total_non_count_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with cleaned data\n",
    "\n",
    "model3 = Pipeline([('vect', TfidfVectorizer()),\n",
    "               #('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model3.fit(X_train_cleaned, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred3 = model3.predict(X_test_cleaned)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred3, y_test))\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7946428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1091\n",
      "           1       0.77      0.73      0.75       813\n",
      "\n",
      "    accuracy                           0.79      1904\n",
      "   macro avg       0.79      0.79      0.79      1904\n",
      "weighted avg       0.79      0.79      0.79      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3_2 = Pipeline([('vect', CountVectorizer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model3_2.fit(X_train_cleaned, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred3_2 = model3_2.predict(X_test_cleaned)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred3_2, y_test))\n",
    "print(classification_report(y_test, y_pred3_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data performed worse... why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------- End of up-to-date material------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-9621dea74106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               ])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit_transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "model4 = Pipeline([('vect', MultiLabelBinarizer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred4, y_test))\n",
    "print(classification_report(y_test, y_pred4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating custom tokens\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def stem_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "stemmed_stopwords = [stemmer.stem(word) for word in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6055672268907563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74      1091\n",
      "           1       0.76      0.11      0.20       813\n",
      "\n",
      "    accuracy                           0.61      1904\n",
      "   macro avg       0.68      0.54      0.47      1904\n",
      "weighted avg       0.66      0.61      0.51      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4 = Pipeline([('vect', TfidfVectorizer(max_features=10,\n",
    "                         stop_words=stemmed_stopwords,\n",
    "                         tokenizer=stem_and_tokenize)),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred4= model4.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred4, y_test))\n",
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nicolemichaud/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Stemming didn't help, what about lemmatization?\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def lem_and_tokenize(document):\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "lemm_stopwords = [lemmatizer.lemmatize(word) for word in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5940126050420168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.99      0.74      1091\n",
      "           1       0.78      0.07      0.13       813\n",
      "\n",
      "    accuracy                           0.59      1904\n",
      "   macro avg       0.68      0.53      0.43      1904\n",
      "weighted avg       0.67      0.59      0.48      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model5 = Pipeline([('vect', TfidfVectorizer(max_features=10,\n",
    "                         stop_words=lemm_stopwords,\n",
    "                         tokenizer=lem_and_tokenize)),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred5= model5.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred5, y_test))\n",
    "print(classification_report(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even worse than stemming...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-ddaec5e7cabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                    \"be removed in 0.24.\")\n\u001b[1;32m   1879\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "sample_submission[\"target\"] = model2.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This MultinomialNB estimator requires y to be passed, but the target y is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-38681ec39147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#count_vectorizer = feature_extraction.text.CountVectorizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 return last_step.fit(Xt, y,\n\u001b[0m\u001b[1;32m    379\u001b[0m                                      **fit_params_last_step).transform(Xt)\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requires_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    417\u001b[0m                     \u001b[0;34mf\"This {self.__class__.__name__} estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This MultinomialNB estimator requires y to be passed, but the target y is None."
     ]
    }
   ],
   "source": [
    "#count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vectors = model2.fit_transform(train_df[\"text\"])\n",
    "test_vectors = model2.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-c949ba4bec41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "y_pred5 = tfidf.predict(X_test_cleaned)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred5, y_test))\n",
    "print(classification_report(y_test, y_pred5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next things to try:\n",
    "- change max num features\n",
    "- try other classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf4 = TfidfVectorizer(max_features=100)\n",
    "\n",
    "# Fit the vectorizer on X_train[\"text\"] and transform it\n",
    "X_train_vectorized4 = tfidf4.fit_transform(X_train[\"text\"])\n",
    "\n",
    "# Visually inspect the vectorized data\n",
    "\n",
    "pd.DataFrame.sparse.from_spmatrix(X_train_vectorized4, columns=tfidf4.get_feature_names())\n",
    "# note that this doesnt have stopwords removed!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr_features_cv = cross_val_score(clf, X_train_vectorized4, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "incr_features_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model3 = LogisticRegression()\n",
    "model3_cv = cross_val_score(model3, X_train_vectorized, y_train, scoring=\"f1\")\n",
    "model3_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building baseline model, try things to improve score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_vectorized = tfidf.fit_transform(train_df)\n",
    "test_df_vectorized = tfidf.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-83d004593746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               ])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \"\"\"\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "#best model:\n",
    "final = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "final.fit(train_df_vectorized, y)\n",
    "\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#y_pred = final.predict(test_df)\n",
    "\n",
    "#print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "#clf.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(evaluate using f1 metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
